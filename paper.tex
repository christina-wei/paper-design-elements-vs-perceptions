%% Manuscript for the effect of designed conversational architecture on the perception of agents
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,screen,review, anonymous]{acmart}

\usepackage[linewidth=1pt]{mdframed}
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{makecell} 

\newcommand{\cmt}[1]{}%{\ignorespaces}


%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2023}
\acmYear{2023}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}
%TC:ignore

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
% \title[short title]{How to Make Pinocchio a Real Boy? Designing conversational architecture elements to achieve desirable anthropomorphized perceptions}
\title[Bot's Guide to Being Human]{Bot's Guide to Being Human: Investigating the Effect of Conversation Architecture Elements on the Anthropomorphized Perceptions of Conversational Agents}
% Blurring the line between human and bots


%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Christina Wei}
\email{christina.wei@mail.utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \country{Canada}
}

\author{Young-Ho Kim}
\email{ygho.kim@navercorp.com}
\affiliation{%
  \institution{Naver Corporation}
  \city{Seoul}
  \country{Korea}
}

\author{Anastasia Kuzminykh}
\email{anastasia.kuzminykh@utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \country{Canada}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Wei, Kim, and Kuzminykh}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  TBD
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{conversational agents, user perception, conversational architecture, social cues}

%%\received{20 February 2007}
%%\received[revised]{12 March 2009}
%%\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
%TC:endignore

\section{Introduction (Not Ready)}

Conversational agents (CAs) are software-based systems, either voice of text-based, designed to interact with humans using natural language. Adoption for CAs such as Alexa (Amazon) or Siri (Apple) are rapidly growing in the market, with half of US internet users own one or more smart speaker devices \cite{2022comscore}. These conversational agents are designed to be ubiquitous, easily accessible through smartphones, tablets, laptops and smart devices. Because these agents leverage natural language for interaction, they solicit social responses from users, encouraging users to attribute lifelike qualities, a.k.a. anthropomorphized perceptions to CAs \cite{eyssel2012if}.

Anthropomorphism is defined as the attribution of traits that we typically associate with being distinctly human to nonhuman entities \cite{waytz2010sees}. For example, users tend to personify conversational agents like Amazon Alexa by using person pronouns instead of object pronouns in online reviews \cite{purington2017alexa}.  Research shows that anthropomorphic design is beneficial to establishing and maintaining trust between users and conversational agents \cite{seeger2021chatbots}. Also, speakers tend to align their lexical choices with conversational agents, similar to human-human conversations \cite{cowan2015does}. Anthropomorphism has been shown to ease user interactions, e.g. making agents more approachable, engaging, and trustworthy when they exhibit human characteristics \cite{qiu2009evaluating}. These processes are of particular interest for human-agent communication because they form the basis for user expectations and predispositions regarding agents' behavior, reliability of the information, etc. \cite{kuzminykh2020genie}.

One of the key factors for anthropomorphized perception is how conversational agents convey information through verbal or non-verbal cues. Studies have found that conversational agents are perceived as more socially present and emotionally intelligent if they use sentiment-adaptive response based on user's utterances, resulting in higher user satisfaction \cite{diederich2019emulating}\cite{yang2017perceived}. Also, CAs that mimic user behaviour through lexical alignment reduce users' cognitive workload, resulting in higher engagement with the interaction \cite{spillner2021talk}. Non-verbal cues such as expressive prosody contribute to higher perceived intimacy with the user, as well as higher perceived enjoyment and ease of use \cite{kim2020can}. However, conversational architecture design may lead to negative consequences, such as an agent with an extroverted personality may be seen as less trustworthy, as users are irritated by the system's overly familiar attitude \cite{andrews2012system}.

Even though there are existing research efforts investigating the effect of various conversational architecture elements on the anthropomorphized perception of agents, there is no clear view on the overall landscape on the state of research to understand what has been studied and what needs more efforts. Some reasons for this gap could be due to the lack of consistency in perception measures such as humanness or empathy. There are various questionnaires used in the studies (e.g. Godspeed Questionnaire) but their definitions for perceptions may be different. Also, there are various confounding factors like prior experience and domain of usage that makes it hard to generalize design principles for anthropomorphized perception of agents.

This paper attempts to address this gap in knowledge by investigating the following research questions: (RQ1) How does the specifics of conversational architecture design affect the anthropomorphized perception of CAs? and (RQ2) How does the specifics of conversational architecture design affect the perception of interaction with CAs? Through a comprehensive review of the existing literature, this paper presents the synthesis of a design framework developed based on X number of paper published between 2010 and 2022. The framework associated four categories of perception - interaction, ability of the agent, human attributes of the agent, and social connections with the user, with four categories of conversational architecture elements - verbal (content, style), visual (CMC), auditory (voice qualities, vocalizations), and chronemics adapted from Feine et al \cite{feine2019taxonomy}.

<One paragraph summarizing results>

<One paragraph outlining contributions to the HCI community>
* Synthesize existing framework into design framework \newline
* Point out gaps in research \newline

In the remainder of the paper, we first review the existing literature on design frameworks for conversational agents and measures of anthropomorphized perceptions. We then describe our literature review and data analysis process, following by describing the design framework synthesized based on findings of the collected literature corpus. Finally, we discuss the critical gaps in research identified through our analysis, and propose key opportunities for future research.


Design the conversational agents


%\section{Literature Review}

%\cite{finch2020towards} Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols

%Synthesis on conversational architecture

%Synthesis on measures

%Connections between conversational architecture elements and measures


\section{Methods}

This section describes the research methodologies for the search procedure, selection criteria and data analysis process.

\subsection{Data Collection}

Following PRISMA guidelines \cite{prisma}, we reviewed and selected literature relevant to the relationships between the specifics of conversation architecture elements and anthropomorphized perceptions of CAs. Searches were carried out in the ACM Digital Library between January 1 and January 15, 2023. During initial analysis, it didn't seem like there were common terms used to refer to either conversation architecture elements, or anthropomorphized perceptions. As such, search terms were kept general to literature related to conversational agents. Based on search terms used in previously published literature reviews \cite{clark2019state}\cite{rapp2021human} , the following keywords have been identified to search for publications related to conversational user interfaces:
\newline

\textit{"conversational agent" OR "natural language interface" OR "IPA" OR "intelligent personal assistant" OR "chatbot" OR "speech interface" OR "voice assistant" OR "intelligent agent" OR "human-chatbot communication" OR "virtual agent" OR "dialog* system" OR "voice user interface" OR "human computer dialog*"}
\newline

The initial query retrieved 2901 unique publications. The following selection criteria are applied to identify literature related to the effect of conversational architecture on perception of agents:
\begin{itemize}
  \item Peer-reviewed publications written in English
  \item Voice-based or text-based conversational agents
  \item Experiment study on the impact of conversation architecture elements on the anthropomorphized perceptions of agents
  \item Impact of conversation architecture elements can be separated from other effects (e.g. embodiment)

\end{itemize}

We screened the titles and abstracts of the papers based on the selection criteria below which resulted in 221 papers. Reviewing the full articles of these publication resulted in 49 papers for analysis. An additional search for related literature was also performed to find new publications, adding 8 more papers to the corpus. We identified 57 relevant articles that met our selection criteria (see Figure \ref{fig:prisma}).

\begin{figure}[h]
  \centering
  \includegraphics[width=1\columnwidth]{fig-prisma.png}
  \caption{Literature search using PRISMA guidelines}
  \label{fig:prisma}
\end{figure}

\subsubsection*{Literature Corpus Characteristics}

The papers reviewed (n=57) were published between May 2011 and November 2022. More than 75\% of the papers were published in or after 2019, with a slight trend upwards over the years (see Figure \ref{fig:paper}). The vast majority of the papers in our corpus were published in conference proceedings (n=50), with the remainder papers published in journals. Out of the papers published in conferences, the top conferences were The ACM Conference on Human Factors in Computing Systems\footnote{https://dl.acm.org/conference/chi} (n=16), Conversational User Interfaces\footnote{https://dl.acm.org/conference/cui} (n=7), Human-Agent Interaction\footnote{https://dl.acm.org/conference/hai} (n=4), and Intelligent Virtual Agents\footnote{https://dl.acm.org/conference/iva} (n=4). 
%Out of the papers published in journals, some venues include the International Journal of Human-Computer Interaction\footnote{https://www.tandfonline.com/journals/hihc20} (n=2) and Interacting with Computers\footnote{https://academic.oup.com/iwc} (n=1).

On the modality characteristics of the conversational agents in the corpus, there is a roughly even split between the modalities, with slightly more papers (n=30) studying voice-based CAs, and the rest (n=27) studying text-based CAs.

\begin{figure}[h]
  \centering
  \includegraphics[width=\columnwidth]{fig-paper.png}
  \caption{Number of papers by year}
  \label{fig:paper}
\end{figure}

\subsection{Data Analysis}

\subsubsection*{Anthropomorphized Perceptions} To study RQ1, the exact quotes of anthropomorphized perception measurements were extracted from each paper. Inductive thematic analysis was used to group these verbatim quotes into codes based on their meanings. For example, the code likeability of the agent contains the questionnaire item "this voice agent was likeable" used by \cite{cuadra2021my}\cmt{[67]}, Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed}'s set of questions on likeability used by \cite{linnemann2018can}\cmt{[15]}, and Subjective Assessment of Speech System Interface (SASSI) questionnaire \cite{hone2000towards}\cmt{sassi}'s set of questions on likeability used by  \cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}. This step resulted in 83 unique codes. The codes are then organized based similarity of the meanings, resulting in 11 basic themes. For example, the basic theme of \textit{personality traits} of the agent contains measurements such as likeability, friendliness, and warmth. Lastly, the 11 basic themes are categorized into 4 organizing themes: \textit{perception of interaction with agent, perception of agent's ability, perception of social connection with agent, and perception of agent's humanness} (Table \ref{tab:perceptions}).

\subsubsection*{Conversation Architecture Elements}
The study RQ2, the conversation architecture elements used in the study were extracted from each paper. Some of the papers were applying multiple elements to the CA design, such as the the anthropomorphic design used in this study \cite{seeger2021chatbots}\cmt{[35]}. In the case where multiple elements were used, the codes broke down the conversation architecture into its core components. For example, the anthropomorphic design used in Seeger et al's study \cite{seeger2021chatbots}\cmt{[35]} was broken down to the elements of emotional expressions, is-typing indicator, emoticons, and response delay to capture as codes. 58 unique codes were created as part of this process, capturing elements like sentiment-adaptive responses \cite{diederich2019emulating}\cmt{[25]}, lexical alignment \cite{spillner2021talk}\cmt{[18]}, and typos \cite{westerman2019believe}\cmt{[9]}. Codes were then organized based on similarity of the elements. For example, the basic theme of \textit{disfluency} contains elements of fillers \cite{jeong2019exploring}\cmt{[10]}\cite{wester2015artificial}\cmt{[14]}, interjections \cite{ceha2022expressive}\cmt{[77]}\cite{hu2021enhancing}\cmt{[56]}, and repetitions \cite{yang2021effect}\cmt{[72]}. Lastly, these basic themes are then categorized into organizing themes adapted from the social cues taxonomy structure by Feine et al \cite{feine2019taxonomy}. Based on this paper, the Verbal-Content category is mapped to our organizing theme of \textit{linguistic content}, and the Verbal-Style category is mapped to our organizing theme of \textit{linguistic style}.
Given our analysis focuses on the text and voice aspects of a conversational agent and does not analyze the embodiment aspects of design, the visual category is not applicable for our analysis. Also, we collapsed the auditory and invisible categories into the organizing theme of \textit{non-linguistic format} (Table \ref{tab:cues}).

\subsubsection*{Relationship Between Anthropomorphized Perceptions and Conversation Architecture Elements}
For RQ3, we extracted the relationships between perceptions and architecture elements from each paper based on the codes developed for anthropomorphized perceptions and conversation architecture elements above, noting whether the architecture element had an impact of on the perceptions. Out of the 57 papers, 264 connections between anthropomorphized perceptions and conversation architecture elements were found. To analyze specifically the relationships between the specifics of conversation architecture that affect the anthropomorphized perceptions of CAs, 69 connections that did not result in significant relationships were discarded, resulting in 195 relationships for analysis. For example, the specific connection between style matching and user satisfaction was discarded because Hoegen et al. \cite{hoegen2019end}\cmt{[31]} did not find a significant difference between the style matching agent and the non-style matching agent for overall interaction satisfaction. Out of the 195 relationships, 185 were relationships between individual architecture elements and perceptions. These single architecture element to perception relationships are visualized as a heatmap based on literature coverage within the literature review corpus, as seen in Figure \ref{fig:heatmap-impact}. Perceptions impacted by the composite of multiple architecture elements in an agent will be discussed in more details in the Composite Architecture Elements section.

\section{Findings}

TBD

\subsection{Anthropomorphized Perceptions}

\begin{table*}[ht]
\renewcommand*{\arraystretch}{1.4}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}p{3.1cm} | p{2cm} | p{4cm} | p{1.5cm} | p{6cm} @{}}
%!{\vrule width 1.2pt} 
\Xhline{1.2pt}
\textbf{Category} & \textbf{Theme} & \textbf{Sample Codes} & \textbf{No. Papers} & \textbf{Papers} 
\\ \Xhline{1.2pt}
\multirow{3}{*}{\parbox{3cm}{Perception of Interaction with Agent}}
    & Usability & accuracy, ease of use, efficiency, helpfulness & 23 
    & \cite{ashktorab2019resilient}\cmt{[88]}
    \cite{ceha2022expressive}\cmt{[77]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{choi2020nobody}\cmt{[54]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{dubiel2020persuasive}\cmt{[60]}
    \cite{elsholz2019exploring}\cmt{[61]}
    \cite{haas2022keep}\cmt{[78]}
    \cite{habler2019effects}\cmt{[63]}
    \cite{healey2013relating}\cmt{[39]}
    \cite{hu2022polite}\cmt{[76]}
    \cite{huiyang2022improving}\cmt{[17]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{kim2019comparing}\cmt{[89]}
    \cite{kim2020can}\cmt{[24]}
    \cite{kraus2020effects}\cmt{[64]}
    \cite{linnemann2018can}\cmt{[15]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{miehle2018exploring}\cmt{[51]}
    \cite{misu2011toward}\cmt{[83]}
    \cite{roy2021users}\cmt{[71]}
    \cite{spillner2021talk}\cmt{[18]}
    \cite{wilhelm2022keep}\cmt{[28]}
\\ \cline{2-5}
    & Engagement & enjoyment, annoyance, desirable, intention to use  & 28
    & \cite{andrews2012system}\cmt{[38]}
    \cite{ceha2022expressive}\cmt{[77]}
    \cite{ceha2021can}\cmt{[57]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{cox2022does}\cmt{[27]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{elsholz2019exploring}\cmt{[61]}
    \cite{fadhil2018effect}\cmt{[52]}
    \cite{gnewuch2022opposing}\cmt{[20]}
    \cite{go2021conversational}\cmt{[80]}
    \cite{healey2013relating}\cmt{[39]}
    \cite{huiyang2022improving}\cmt{[17]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{kim2020can}\cmt{[24]}
    \cite{kim2019comparing}\cmt{[89]}
    \cite{lee2020hear}\cmt{[23]}
    \cite{linnemann2018can}\cmt{[15]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{miehle2018exploring}\cmt{[51]}
    \cite{miyamoto2017improving}\cmt{[46]}
    \cite{moilanen2022measuring}\cmt{[82]}
    \cite{roy2021users}\cmt{[71]}
    \cite{spillner2021talk}\cmt{[18]}
    \cite{volkel2021examining}\cmt{[69]}
    \cite{volkel2022user}\cmt{[75]}
    \cite{xiao2021let}\cmt{[73]}
    \cite{yang2021effect}\cmt{[72]}
    \cite{zhu2022effects}\cmt{[26]}    
\\ \cline{2-5}
    & Satisfaction & service satisfaction, quality of interaction & 12
    & \cite{ceha2022expressive}\cmt{[77]}
    \cite{choi2020nobody}\cmt{[54]}
    \cite{diederich2019emulating}\cmt{[25]}
    \cite{elsholz2019exploring}\cmt{[61]}
    \cite{habler2019effects}\cmt{[63]}
    \cite{gnewuch2018faster}\cmt{[19]}
    \cite{hoegen2019end}\cmt{[31]}
    \cite{hu2022polite}\cmt{[76]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{roy2021users}\cmt{[71]}
    \cite{wilhelm2022keep}\cmt{[28]}
    \cite{yang2017perceived}\cmt{[44]}
\\ \Xhline{1.2pt} 
\multirow{3}{*}{\parbox{3cm}{Perception of Agent's Ability}}
    & Intelligence & knowledgeable, intelligent, expertise & 11
    & \cite{ashktorab2019resilient}\cmt{[88]}
    \cite{ceha2021can}\cmt{[57]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{dubiel2020persuasive}\cmt{[60]}
    \cite{feijoo2021effects}\cmt{[70]}
    \cite{hu2021enhancing}\cmt{[56]}
    \cite{jeong2019exploring}\cmt{[10]}
    \cite{spillner2021talk}\cmt{[18]}
    \cite{volkel2022user}\cmt{[75]}
    \cite{yang2017perceived}\cmt{[44]} 
\\ \cline{2-5}
    & Competence & competent, capable & 4 
    & \cite{cox2022does}\cmt{[27]}
    \cite{kraus2020effects}\cmt{[64]}
    \cite{lee2019s}\cmt{[55]}
    \cite{westerman2019believe}\cmt{[9]}
\\ \cline{2-5}
    & Trust & credibility, trustworthy, truthfulness, confidence & 15
    & \cite{andrews2012system}\cmt{[38]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{dubiel2020persuasive}\cmt{[60]}
    \cite{fadhil2018effect}\cmt{[52]}
    \cite{healey2013relating}\cmt{[39]}
    \cite{hoegen2019end}\cmt{[31]}
    \cite{huiyang2022improving}\cmt{[17]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{kraus2020effects}\cmt{[64]}
    \cite{lee2020hear}\cmt{[23]}
    \cite{linnemann2018can}\cmt{[15]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{seeger2021chatbots}\cmt{[35]}
    \cite{tolmeijer2021female}\cmt{[62]}
    \cite{wilhelm2022keep}\cmt{[28]}    
\\ \Xhline{1.2pt} 
\multirow{3}{*}{\parbox{3cm}{Perception of Social Connection with Agent}}
    & Conversation Tone & appropriate, expressive, empathetic, persuasive & 13 
    & \cite{chan2021kinvoices}\cmt{[74]}
    \cite{cox2022does}\cmt{[27]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{daher2020empathic}\cmt{[58]}
    \cite{diederich2019emulating}\cmt{[25]}
    \cite{dubiel2020persuasive}\cmt{[60]}
    \cite{hu2021enhancing}\cmt{[56]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{misu2011toward}\cmt{[83]}
    \cite{tolmeijer2021female}\cmt{[62]}
    \cite{yang2021effect}\cmt{[72]}
    \cite{yang2017perceived}\cmt{[44]}
    \cite{zhu2022effects}\cmt{[26]}           
\\ \cline{2-5}
    & Social Presence & connectedness, familiarity, similarity, psychological distance & 18
    & \cite{ceha2022expressive}\cmt{[77]}
    \cite{ceha2021can}\cmt{[57]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{choi2020nobody}\cmt{[54]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{diederich2019emulating}\cmt{[25]}
    \cite{gnewuch2018faster}\cmt{[19]}
    \cite{gnewuch2018chatbot}\cmt{[21]}
    \cite{gnewuch2022opposing}\cmt{[20]}
    \cite{go2021conversational}\cmt{[80]}
    \cite{khooshabeh2011does}\cmt{[37]}
    \cite{kim2020can}\cmt{[24]}
    \cite{lee2019s}\cmt{[55]}
    \cite{lubis2019positive}\cmt{[43]}
    \cite{lubold2016effects}\cmt{[86]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{niewiadomski2013laugh}\cmt{[85]}
    \cite{westerman2019believe}\cmt{[9]}    
\\ \cline{2-5}
    & Intimacy & intimate, rapport, quality of relationship & 7 
    & \cite{choi2020nobody}\cmt{[54]}
    \cite{khooshabeh2011does}\cmt{[37]}
    \cite{kim2020can}\cmt{[24]}
    \cite{lee2020hear}\cmt{[23]}
    \cite{linnemann2018can}\cmt{[15]}
    \cite{lubold2016effects}\cmt{[86]}
    \cite{westerman2019believe}\cmt{[9]}
\\ \Xhline{1.2pt}
\multirow{2}{*}{\parbox{3cm}{Perception of Agent's Humanness}}
    & Human-likeness & human-like, natural, artificial, machine-like & 20
    & \cite{ashktorab2019resilient}\cmt{[88]}
    \cite{ceha2021can}\cmt{[57]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{choi2020nobody}\cmt{[54]}
    \cite{cox2022does}\cmt{[27]}
    \cite{diederich2019emulating}\cmt{[25]}
    \cite{gnewuch2018faster}\cmt{[19]}
    \cite{haas2022keep}\cmt{[78]}
    \cite{hu2022polite}\cmt{[76]}
    \cite{jeong2019exploring}\cmt{[10]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{lubis2019positive}\cmt{[43]}
    \cite{ma2022ask}\cmt{[29]}
    \cite{misu2011toward}\cmt{[83]}
    \cite{niewiadomski2013laugh}\cmt{[85]}
    \cite{ouchi2019should}\cmt{[59]}
    \cite{seeger2021chatbots}\cmt{[35]}
    \cite{wester2015artificial}\cmt{[14]}
    \cite{westerman2019believe}\cmt{[9]}
    \cite{zhu2022effects}\cmt{[26]}    
\\ \cline{2-5}
    & Personality Traits & friendly, kind, warm, creepy, likeable, polite & 27
    & \cite{andrews2012system}\cmt{[38]}
    \cite{ashktorab2019resilient}\cmt{[88]}
    \cite{ceha2022expressive}\cmt{[77]}
    \cite{ceha2021can}\cmt{[57]}
    \cite{chan2021kinvoices}\cmt{[74]}
    \cite{cox2022does}\cmt{[27]}
    \cite{cuadra2021my}\cmt{[67]}
    \cite{haas2022keep}\cmt{[78]}
    \cite{habler2019effects}\cmt{[63]}
    \cite{healey2013relating}\cmt{[39]}
    \cite{hu2022polite}\cmt{[76]}
    \cite{huiyang2022improving}\cmt{[17]}
    \cite{jeong2019exploring}\cmt{[10]}
    \cite{jestin2022effects}\cmt{[81]}
    \cite{khooshabeh2011does}\cmt{[37]}
    \cite{kim2019comparing}\cmt{[89]}
    \cite{lee2019s}\cmt{[55]}
    \cite{lee2020hear}\cmt{[23]}
    \cite{linnemann2018can}\cmt{[15]}
    \cite{miehle2018exploring}\cmt{[51]}
    \cite{moilanen2022measuring}\cmt{[82]}
    \cite{ouchi2019should}\cmt{[59]}
    \cite{tolmeijer2021female}\cmt{[62]}
    \cite{volkel2021manipulating}\cmt{[68]}
    \cite{volkel2022user}\cmt{[75]}
    \cite{wester2015artificial}\cmt{[14]}
    \cite{zhu2022effects}\cmt{[26]} 
\\ \Xhline{1.2pt}
\end{tabular}%
}
\caption{Perception measures}
\label{tab:perceptions}
\end{table*}

As shown in Table \ref{tab:perceptions}, there are four organizing themes defined for the anthropomorphized perceptions of conversational agents covering 11 basic themes of perception. The details of each theme are discussed below.

\textbf{Perception of interaction with agent} evaluates the overall interaction quality users had with the conversational agent. The three basic themes for this perceptions are usability, engagement and satisfaction. \textit{Usability} measures the utilitarian aspects of the interaction, whether it was accurate, easy to use, efficient or helpful. Some commonly used methods to measure usability include the response accuracy portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, or the NASA Task Load Index (NASA-TLX) \cite{hart1988development}\cmt{nasa} to measure cognitive workload. Questions such as "the system is easy to use" or "it is easy to understand the agent" are also measures of usability. \textit{Engagement} on the other hand measures users' emotional reactions, whether they have enjoyed the conversation with CA, or annoyed or frustrated with the interaction. Some commonly used methods to measure engagement include  the annoyance portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, and the Use Engagement Scale (UES) \cite{o2018practical}\cmt{ues}. Questions such as "I enjoyed using the system" or "I felt frustrated with the agent" are also measures of engagement. Lastly, \textit{Satisfaction} measures users' overall satisfaction interacting with the agent. Questions such as "the overall assessment of conversing with the CA was satisfactory" are used to measure this perception.

\textbf{Perception of agent's ability} evaluates the perceived capabilities of the agent. While there are some elements of system performance in this measure, the main aspect we are interested in is the perception differences for agents with identify system capabilities but with different architecture elements. Specifically, \textit{intelligence} measures the agent's expertise and knowledge, and it is commonly administered through the Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} on the set of questions related to perceived intelligence. Also survey questions such as asking users about the agent's intelligence and domain knowledge are used to measure perceived intelligence. \textit{Competence} takes intelligence one step further by evaluating the agent's ability to put its intelligence into practice. To measure a CA's competence, there are usually surveys or qualitative feedback that the agent is capable and competent, and that the users have confidence in the agent's ability to get the job done. Lastly, \textit{trust} evaluates agent's truthfulness, credibility and benevolence. Some commonly used methods to evaluate trust include the Trust Propensity Scale \cite{mayer1999effect} and the Individualized Trust Scale (ITS) \cite{wheeless1977measurement}. Questions such as "is the agent honest" and "can I trust the agent with sensitive information" are also measures of trust.

\textbf{Perception of the social connection with agent} evaluates the emotional connections that users have with agents. The three basic themes of conversation tone, social presence and intimacy are included in this category. \textit{Conversation tone} measure the affective impression of the agent's tone, such as empathy, expressiveness, or passionate. Also, it measures whether the tone used by the agent is persuasive or appropriate for the conversation. \textit{Social presence} measures the sense of connectness and psychological distance users has with an agent. Some aspects in this measure include a sense of familiarity or similarity with the agent, whether users feel the agent behaves like them or have similar attitudes to them. The measure of \textit{Intimacy} extends social presence into the realm of the quality of relationships with an agent. Some commonly used measures include the set of social attraction questions from the interpersonal attraction questionnaire \cite{mccroskey1975development} and the quality of relationship inventory (QRI) \cite{pierce1997assessing}. These questionnaires include questions like "I think the agent could be a friend of mine", or "I feel we could establish a personal relationship with each other".

\textbf{Perception of agent's humanness} evaluates human-likeness and the anthropomorphized personality traits that users assign to agents. \textit{Human-likeness} measures whether the agent presented itself as natural and human-like, or artificial and machine-like. The Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} set of questions related to anthropomorphism and the Ascent of Man scale \cite{kteily2015ascent} are commonly used methods to assess human-likeness. Survey questions with semantic scales such as "human-like / machine-like" and "artificial / natural" are also used for this perception. \textit{Personality traits} captures the human characteristics that are attributes to the agent, such as warm, friendly, likeable, and polite. This is commonly captured in the qualitative feedback from users, commenting on whether the agent is extroverted or introverted, or the human characteristics they perceive the agent such as funny or witty. Some studies used the measure of the Big-5 personality traits \cite{gosling2003very} to map an agent's disposition on various personality dimensions.

Overall there is good coverage of perception measures based on the list of papers reviewed in our corpus. The most commonly measured perceptions are related to the interaction with agent, followed by the perception of agent's humanness. There are two basic themes that are the least measured compared to the others: competence under the perception of agent's ability, and intimacy under the perception of social connection with agent. This may be due to the controlled lab settings for the experiments, where participants are given the scenarios for interaction. This environment is not conducive to forming relationships with a conversational partner, as noted by Linnerman et al. in their discussions \cite{linnemann2018can}\cmt{[15]}. Also, the same factor could impact the assessment of agent's abilities, as the users may not feel like they have the expertise to assess an agent's competence. These factors could contribute to the reasons why competency and intimacy are not as frequently measured in experimental studies.

% Add citations

\subsection{Conversation Architecture Elements}

As shown in Table \ref{tab:cues}, there are three categories defined for the conversation architecture elements covering 10 different themes. The details of each category and theme are discussed below.

The category of \textbf{linguistic content} maps to the content category under verbal cues in Feine et al's taxonomy, which refers to elements expressed with written or spoken words that are related to the strict and literal meaning of a message (i.e. what is said) \cite{feine2019taxonomy}. The theme of \textit{affective language} captures the injection of emotional words or phrases into the agent's utterance, such as affective expressions \cite{seeger2021chatbots}\cmt{[35]}\cite{yang2017perceived}\cmt{[44]}\cite{zhu2022effects}\cmt{[26]}, sentiment-adaptive responses \cite{diederich2019emulating}\cmt{[25]}, and encouraging words \cite{healey2013relating}\cmt{[39]}. \textit{Social talk} captures non-task related conversations with the user to build social connection, such as self-disclosure \cite{lee2020hear}\cmt{[23]} and social dialogue \cite{volkel2021manipulating}\cmt{[68]}\cite{lubold2016effects}\cmt{[86]}. The theme of \textit{humour} is similar to social talk but specific to CA's attempt to include jokes in its utterances. The separation of social talk and humor is based on findings from previous research, where user's attitude towards humour is different between human-human conversations vs. human-agent conversations \cite{clark2019makes}. We would like to capture the relationship between humour and agent perceptions differently from social talk. Lastly, the theme of \textit{agent-initiated content} captures utterances that are driven by the agent without direct prompts from the user. This elements in this theme include conversation repairs \cite{cuadra2021my}\cmt{[67]}\cite{ashktorab2019resilient}\cmt{[88]} and proactive content like eliciting feedback \cite{xiao2021let}\cmt{[73]}.

The category of \textbf{linguistic style} maps to the style category under verbal cues in Feine et al's taxonomy, which refers to elements expressed with written or spoken words that are related to the meaningful deployment of language variation in a message (i.e. how something is said) \cite{feine2019taxonomy}. The theme of \textit{formality} describes the language style used by the conversational agent, whether it is formal vs. casual, such as using honorific expressions to address users \cite{ouchi2019should}\cmt{[59]}. \textit{Alignment} captures the degree that the agent aligns its utterances to the users, such as lexical alignment on the content and structural of the sentences \cite{huiyang2022improving}\cmt{[17]}\cite{linnemann2018can}\cmt{[15]}, as well as agreement with the user \cite{volkel2021examining}\cmt{[69]}. \textit{Elaborateness} captures the sentence complexity and length of the utterances. For example, Roy et al. explored the differences in perception for variations in elaborateness such as "Cloudly, possibility of snow, high: 4, low: -10" vs "Today will be cloudy, with a high of 4 and a low of -10. Snow is predicted" \cite{roy2021users}\cmt{[71]}. Lastly, the category of \textit{disfluency} captures the style of using non-lexical utterances like filler words ("um, uh") \cite{hu2021enhancing}\cmt{[56]}\cite{jeong2019exploring}\cmt{[10]}, or repetition of words within a sentence \cite{yang2021effect}\cmt{[72]}. 

Lastly, the category of \textbf{non-linguistic format} maps loosely to the elements in auditory and invisible categories in Feine et al's taxonomy \cite{feine2019taxonomy}. These are auditory or textual variations in the presentation of the agent's utterances. In the theme of \textit{prosodic cue}, it captures vocal qualities like gender of voice \cite{habler2019effects}\cmt{[63]}\cite{jestin2022effects}\cmt{[81]}, and speech rate \cite{choi2020nobody}\cmt{[54]}. \textit{Text variations} include different formats that text-based agents use to present information to users, like emoticons \cite{kim2019comparing}\cmt{[89]}\cite{wilhelm2022keep}\cmt{[28]}, typos \cite{westerman2019believe}\cmt{[9]}, and response delays \cite{gnewuch2022opposing}\cmt{[20]}\cite{seeger2021chatbots}\cmt{[35]}.

Overall the spread of conversation architecture elements relevant to anthropomorphized perceptions are evenly distributed across linguistic content, linguistic style, and non-linguistic format.  Looking at the different themes, there is good coverage of studies on the impact of affective language and prosodic cues on anthropomorphized perceptions. However, it seemed like there is a lack of studies exploring the effect of agent-initiative content on the perception of agents. There are various existing literature on this theme such as conversation repairs \cite{komatani2010online}\cite{reinkemeier2022repair} and agent proactively sharing content with users \cite{dubiel2019inquisitive}\cite{zargham2022understanding}, but they were not included in this systematic literature review because they did not have measures of anthropomorphized perceptions of the CA. This may be because conversations with CAs have historically being driven by the user, with some recent effort to understand the opportunities to be more proactive \cite{cowan2023introduction}, as existing research are focused on the functional aspects of designing an agent instead of exploring into the anthropomorphized perceptions.

Modality?


\begin{table*}[h]
%\resizebox{\textwidth}{!}{
\begin{tabular}{@{}lllc@{}}
\toprule
 \textbf{Category} & \textbf{Theme}      & \textbf{Sample Codes}                                      & \textbf{No. Papers} \\ \midrule
\multirow{4}{*}{Linguistic Content}    & Affective Language & emotional expressions, sentiment-adaptive responses & 11 \\
 & Social Talk           & self-disclosure, social dialogue                       & 7                                       \\
 & Humour                & humorous content, jokes                                & 5                                       \\
 & Agent-Initiated Content & elicit user feedback, proactivity, conversation repair & 4                                       \\ \midrule
\multirow{4}{*}{Linguistic Style}     & Formality          & formal vs. casual, honorific expressions                               & 9  \\
 & Alignment             & content matching, lexical alignment, agreeableness     & 7                                       \\
 & Elaborateness         & elaborate, concise, sentence structure                 & 6                                       \\
 & Disfluency            & fillers, interjections, repetitions                    & 6                                       \\ \midrule
\multirow{2}{*}{Non-Linguistic Format}     & Prosodic Cue            & pitch, intonation, speech rate, spoken accent                          & 12 \\
 & Text Variation        & typo, capitalization, emoticons, response delay & 9                                         \\ \bottomrule 
\end{tabular}%
%}
\caption{Conversation architecture elements}
\label{tab:cues}
\end{table*}

\subsection{Relationship Between Anthropomorphized Perceptions and Conversation Architecture Elements}

\begin{figure*}[]
  \centering
  \includegraphics[width=\textwidth]{fig-heatmap-impact.png}
  \caption{Heatmap of literature for perception of conversational agents for each type of conversational architecture element}
  \label{fig:heatmap-impact}
\end{figure*}

We extracted 265 connections between anthropomorphized perceptions and conversation architecture elements from our reviewed corpus. Out of these connections, 193 of them had an impacted relationship between the conversational architecture elements and anthropomorphized perceptions. Most of these relationships (n=183) were exploring the effect of a single conversation architecture element on perceptions of agents (e.g. \cite{miehle2018exploring}\cmt{[51]}\cite{westerman2019believe}\cmt{[9]}), while a few of them (n=10) used a composite of architecture elements in the study (e.g. \cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2021manipulating}\cmt{[68]}). The 183 single element relationships are visualized into a heatmap (Figure \ref{fig:heatmap-impact}) to based on the number of impacts conversational architecture elements had on the anthropomorphized perceptions. These relationships are discussed in details in the following sections for each perception category.

%\subsubsection{Overall Characteristics}

%While the number of papers studying voice (n=27) vs. text (n=30) modalities is not significantly different, there are some interesting trends in the perceptions studied for CAs with different modalities. Overall, there are less perceptions of agent studied for text-based agents (n=101) as compared to voice-based agents (n=163).
 
%This is especially evident in the perception of social connection with agent and perception of agent's humanness. For the perception of social connection with a CA, there are only 19 perceptions measured for text-based agents, while there are 35 perceptions measured for voice-based agents. Similarly for perception of agent's humanness, there are 36 perceptions measured for text-based agents, as compared to 52 perceptions of voice-based agents. This highlights that there is a ..


\subsubsection{Perception of Interaction with Agent}

The effects of conversation architecture elements on the perception of interaction with agent is the most explored connections in the corpus (n=100). Out of these explored connections, the majority of them (n=69) discovered an impact between the studied architecture element and the perception. For the impacted relationships, the corpus had similar numbers of connections across voice-based (n=34) and text-based (n=35) CAs.

Across the themes in this perception category, both \textbf{usability} and \textbf{engagement} perceptions were measured frequently in our corpus, with conversation architecture elements having effects on these measures across linguistic content, linguistic style and non-linguistic format categories. \textbf{Satisfaction} measures were used in some studies but it is not evaluated as often as engagement or usability. Several papers that measured satisfactions were conversation agents within the transaction context, especially within the customer service domain (e.g. \cite{diederich2019emulating}\cmt{[25]}\cite{elsholz2019exploring}\cmt{[61]}\cite{gnewuch2018faster}\cmt{[19]}). For the relationships across conversation architecture element categories, linguistic style has the higher number of relationships with perceptions of interaction (n=31). Linguistic content (n=17) and non-linguistic format (n=18) had similar number of relationships.

There are a few conversation architecture elements that are notable to the perception of interaction with agent. First are the linguistic styles of formality and elaborateness, where they have high impacts across usability, engagement and satisfaction perceptions. For \textbf{formality}, various studies reported significant differences between using casual vs. formal styles. Some participants enjoyed the friendly nature of the casual style of the conversation \cite{cox2022does}\cmt{[27]}, while in another study participants reported the formal language style as boring \cite{kim2019comparing}\cmt{[89]}. For \textbf{elaborateness}, participants generally found the use of full sentences more useful than keyword only \cite{haas2022keep}\cmt{[78]}\cite{roy2021users}\cmt{[71]}. Otherwise, the impact of an agent's elaborateness on user's perception of interaction depends on the user's preference \cite{miehle2018exploring}\cmt{[51]}, as well as the topic of discussion \cite{haas2022keep}\cmt{[78]}. Within the linguistic content category, \textbf{social talk} and \textbf{humour} conversation architecture elements had impacts on user's perception of the interaction with an agent. There may be some opposing effects between different perceptions of interaction, as users enjoyed conversing with CAs using social talk more \cite{lee2020hear}\cmt{[23]}\cite{roy2021users}\cmt{[71]}, but the tradeoff is that they perceive it as less efficient \cite{roy2021users}\cmt{[71]}. Lastly, majority of the studies found that non-linguistic formats of a CA impacts the perception of the interaction, as \textbf{prosodic cues} such as expressiveness increased participants' engagement ratings \cite{zhu2022effects}\cmt{[26]}, and text variations such as using response delay increased user's satisfaction with the chatbot interaction \cite{gnewuch2018faster}\cmt{[19]}.

\subsubsection{Perception of Agent's Ability}

The effects of conversation architecture elements on the perception of agent's ability is the least explored connection in the corpus (n=35). Out of these explored connections, 27 relationships had an effect between the studied architecture elements and ability perceptions. For these impactful relationships, the corpus had similar numbers of connections across voice-based (n=15) and text-based (n=12) CAs.

Across the themes in this perception category, \textbf{competence} had the smallest number of relationships in our corpus compared to intelligence and trust. Some studies discussed that the perception of competence is dependent various influencing factors, such as task difficulty \cite{kraus2020effects}\cmt{[64]}. Overall, studies on the perception of \textbf{intelligence} had impactful results, such as the use of formal language made the CA seem more knowledgeable \cite{volkel2022user}\cmt{[75]}. However, some evidence suggest that there are nuances to this perception, as a filler-speaking agent was perceived as less intelligent in task-oriented conditions, but was seen as slightly more intelligent in social-oriented conditions \cite{jeong2019exploring}\cmt{[10]}.

For the conversation architecture categories related to the perception of agent's ability, all 10 explored connections related to \textbf{linguistic content} had impacted user's perception. Specifically, CAs utilizing \textbf{agent-initiative content} such as using proactive dialogue and conversation repair strategies are seen as more competent \cite{kraus2020effects}\cmt{[64]} and intelligent \cite{ashktorab2019resilient}\cmt{[88]}. However, the effect of being proactive on user's trust with an agent may be dependent on the proactive style of the user's own conversation patterns \cite{kraus2020effects}\cmt{[64]}. For CAs using \textbf{affective language}, some studies found that using more expressive words increased intelligence and competence \cite{lee2019s}\cmt{[55]}\cite{yang2017perceived}\cmt{[44]}, but it may decrease the perceived trustworthiness of an agent 
%as discussed in Healey et al's study using an agent with an encouraging personality
\cite{healey2013relating}\cmt{[39]}.

The conversation architecture categories \textbf{Linguistic style} and \textbf{non-linguistic format} had mixed results, with some elements demonstrating relationships with the perception of the agent's abilities, while some others didn't. Most these mixed results came from relationships with the perception of trust. Studies with \textbf{alignment} found differences in trust rating in the interaction studies \cite{hoegen2019end}\cmt{[31]}, while some others did not reveal any differences \cite{huiyang2022improving}\cmt{[17]}. Also, research method may impact the perception of trust, as an observation study and interaction study on a similar topic yielded different results on the perception of trust \cite{linnemann2018can}\cmt{[15]}. The use of \textbf{prosodic cues} also had varied impacts on trust, as one study found that differences in vocal cues lead to a difference in perceived truthfulness \cite{dubiel2020persuasive}\cmt{[60]}, while another study using gendered voices did not find any statistically significant differences in perceived trust \cite{jestin2022effects}\cmt{[81]}.

\subsubsection{Perception of Social Connection with Agent}

There are 53 explored connections between conversation architecture elements and the perception of social connection with agents, with majority of them (n=40) resulted in relationships with effects. Interestingly, studies explored more perceptions of social connection with agent related to voice-based CAs (n=34) compared to text-based CAs (n=19), potentially due to the assumption that voice-based agents is more suitable to cultivate human-agent relationships. There are some mixed results for voice-based CAs, as 10 out of the 34 connections did not find any significant results. Half of the neutral results come from the conversation architecture element of \textbf{prosodic cues}. For example, the pitch of agents' voices did not impact the perceived rapport \cite{lubold2016effects}\cmt{[86]} between agent and users or the appropriateness of tone \cite{jestin2022effects}\cmt{[81]}. However, there are also findings that the use of vocal cues made the agent sound more empathetic \cite{tolmeijer2021female}\cmt{[62]}, as well as increased perceived emotional connection \cite{chan2021kinvoices}\cmt{[74]}\cite{kim2020can}\cmt{[24]}. This shows that there are nuanced factors within prosodic cues that impact the perception of social connections that we have not captured in our relationships.

Across the themes in this perception category, \textbf{social presence} (n=17) and \textbf{conversation tone} (n=18) have similar number of relationships between architecture elements and perceptions, but \textbf{intimacy} (n=5) has less number of impactful relationships. One reason for this is half of the explored connections did not have any effect on the perception of social connection, such as the use of capitalization \cite{westerman2019believe}\cmt{[9]}, lexical alignment \cite{linnemann2018can}\cmt{[15]}, or social dialogue \cite{lubold2016effects}\cmt{[86]}. For \textbf{social presence}, conversation architecture elements from \textbf{non-linguistic format} category, prosodic cue and text variation, had a number of impactful relationships in the reviewed studies. For example, participants conversing with the agents using kin's voices experienced significantly higher perceived co-presence where there is a closer psychological connection with the agent \cite{chan2021kinvoices}\cmt{[74]}. Also, text-based agents including a delay before responding to users were rated higher in social presence ratings compared to the agent that did not use any response delays \cite{gnewuch2018faster}\cmt{[19]}\cite{gnewuch2022opposing}\cmt{[20]}. Lastly, the use of \textbf{prosodic cues} can impact the perceived \textbf{conversation tone} of the agent as emotionally expressive \cite{zhu2022effects}\cmt{[26]} or persuasive \cite{chan2021kinvoices}\cmt{[74]}, as well as the appropriateness of the tone used by the agent \cite{jestin2022effects}\cmt{[81]}\cite{misu2011toward}\cmt{[83]}.

Looking at the different categories of conversation architecture cues, the heatmap (Figure \ref{fig:heatmap-impact} shows that there are not many relationships in \textbf{linguistic style} that are related to the perceived social connection with CAs. There are not many explored connections in our reviewed corpus between the two, which could be an indication of the assumption that linguistic style does not impact the perception of social connections.
While we discussed the impact of non-linguistic elements of prosodic cues and text variations earlier, the conversation architecture elements in the linguistic content category also had effects on the perception of social connections. Specifically, CAs using of \textbf{affective language} were perceived to be more empathetic \cite{daher2020empathic}\cmt{[58]}\cite{diederich2019emulating}\cmt{[25]}\cite{yang2017perceived}\cmt{[44]} and emotionally expressive \cite{zhu2022effects}\cmt{[26]}, and emotional connection with the agent \cite{lee2019s}\cmt{[55]}\cite{lubis2019positive}\cmt{[43]}.

%add text variation in the discussion

\subsubsection{Perception of Agent's Humanness}

Agent's humanness is the second most explored perception within our reviewed corpus (n=76), with majority of the connections finding impacted relationship between the studied conversation architecture elements and the perception of agent's humanness (n=56). While the connections were explored more for voice-based agent (n=49) as compared to text-based agents (n=27), the actual impacted relationships between the modalities were similar (voice=32, text=24). This is due to larger number of neutral relationships within voice modality, such as the use of affective language for a speech agent did not impact its perceived likeability \cite{hu2022polite}\cmt{[76]}.

Across the themes in this perception category, both \textbf{human-likeness} and \textbf{personality traits} have relationships with almost all conversation architecture elements. Based on the reviewed corpus, it seems like all the conversation architecture elements extracted from literature have some impact on the perception of agent's humanness. However, the impacts can be both positive or negative. In the case of Chan et al's study \cite{chan2021kinvoices}\cmt{[74]}, participated rated the agent using kin voices as significantly more likeable compared to the generic voices, but it was perceived as eerie. As for the perceptions within this category, there are more relationships for perceived personality traits (n=33) vs. human-likeness (n=18). This is because many studies only have one measure for human-likeness (e.g. artificial or human-like), but have multiple aspects of personality to be explored. For example, participant rated the agent using affective language as more polite, as well as reflected that the agent seemed friendly \cite{hu2022polite}\cmt{[76]}. 

For the conversation architecture elements, formality in the linguistic style category and prosodic cue in the non-linguistic format category had more effects on the perception of agent's humanness in the reviewed corpus. For \textbf{formality}, agents using casual style is perceived as more human-like with a warm, kind and entertaining personality \cite{cox2022does}\cmt{[27]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2019comparing}\cmt{[89]}. The use of \textbf{prosodic cues} varying pitch, intonation and speech rate of a conversation agent generally had impacts on the perceived humanness instead of personality traits \cite{choi2020nobody}\cmt{[54]}\cite{jestin2022effects}\cmt{[81]}\cite{misu2011toward}\cmt{[83]}. For the architecture elements of \textbf{disfluency}, the type of impact on the perception of humanness depended on the context of the conversation. Studies have found that participants perceived the filler-condition agent as more likeable in the social-oriented situation, but did not find the same effect in task-oriented situations \cite{jeong2019exploring}\cmt{[10]}\cite{wester2015artificial}\cmt{[14]}.





%-------------
\section{Discussions}

\subsection{Research Challenges and Opportunities}

%Three major needs emerged from the trends identified by our review: 1) 2) 3).

\subsubsection{Inconsistencies in Perception Measures}

A major roadblock in synthesizing the findings from existing academic research is the diversity and inconsistency of measurements towards the anthropomorphized perception of agents. It is difficult to assess whether perception measures should be compared with each other. Also, some measures combined anthropomorphized perceptions into a composite score, which makes it impossible to separate the perceptions into more granular details.

Based on the literature reviewed in this paper, we noticed that similar perception concepts were \textbf{measured in different ways} through different surveys. For example, there are several approaches to measure the perceived \textit{human-likeness} of an agent. A commonly used survey is adapted from the Godspeed questionnaire \cite{bartneck2009measurement}, which measures human-likeness based on user's impression of the agent as fake / natural, machinelike / humanlike, unconscious / conscious, and artificial / lifelike (used by \cite{hoegen2019end}\cmt{[31]}, \cite{jeong2019exploring}\cmt{[10]} and \cite{ouchi2019should}\cmt{[59]}). Another way to measure human-likeness is adapted from Holtgraves et al.'s \cite{holtgraves2007perceiving} questionnaire, which asks users to assess the agent's perceived human-likeness, skillfulness, thoughtfulness, politeness, responsiveness and engagement (used by \cite{diederich2019emulating}\cmt{[25]} and  \cite{gnewuch2018faster}\cmt{[19]}). One study \cite{westerman2019believe}\cmt{[9]} used the Ascend of Man pictorial scale \cite{kteily2015ascent} as the measure of perceived human-likeness. It is unclear whether these different measures of perceived human-likeness are similar enough to be compared with each other.

 In addition to different methods used to measure for the same perception, our detailed analysis revealed that the measures using the same label may have \textbf{drastically different meanings}. In Diedrech et al.'s study \cite{diederich2019emulating}\cmt{[25]}, \textit{empathy} measure is adapted from \cite{yan2013role} assessing whether the CA gives users individual or personal attention. In Daher et al.'s study \cite{daher2020empathic}\cmt{[58]}, they also measure the perception of empathy, but it is using the RoPE Scale \cite{charrier2019rope} with questions like "the robot cares about my feelings" or "the robot comforts me when I am upset." These two different measures of empathy seem to have different underlying meanings, one assessing the personalization aspect of CAs, while the other is assessing the emotional aspect of CAs. Another example is the measurement of \textit{trustworthiness}, with some constructs measuring the level of sensitive information user's are willing to share \cite{dinev2006privacy}, and some measuring the honesty and truthfulness of an agent \cite{lee2017enhancing}. 

Lastly, there are \textbf{composite measures} of anthropomorphized perception across different categories, making it difficult to break down perceptions into granular details for analysis. One such example is Ma et al's study \cite{ma2022ask}\cmt{[29]} on different approaches for CAs to reply to users' uncertain queries. UX score is used to measure the perception of an agent, which asks whether the user thinks the CA's response is pleasing / trustworthy / natural / acceptable / shorten the distance between CA and user. While the study has found significant impact of the use of formal language on UX score, it is not possible to breakdown the measure into perceptions of interaction (pleasing, acceptable), social connection (shorten the distance between CA and user), and humanness (natural, trustworthy). Similar for Hoegen et al.'s study \cite{hoegen2019end}\cmt{[31]} on the impact of conversational style matching, it is not possible to separate the overall interaction score into different perceptions as the composite measure contains questions measuring different categories of perceptions like interaction (engaging) and humanness (trust, likable).

In recent years there has been some effort towards unifying the evaluation of conversational agents, such as the work by Finch et al. \cite{finch2020towards} presenting a comprehensive analysis of current evaluation protocols. More work is needed to categorize and consolidate perception measures to make them consistent and comparable across various studies. 

%For discussions on mental well beings, agent using emojis is rated higher for attitude (emotional connection) . However, for agent with discussing physical well being, agent using emojis is rated as lower for attitude. 
%Attitude has emotional connection, coherent - coherent is an ability perception, vs. emotional connection is a social connection perception. \cite{fadhil2018effect}\cmt{[52]}


\subsubsection{Other Influencing Factors}

While the discussion in the Framework section above focuses on the overall effect of conversational architecture elements on anthropomorphized perceptions,  there are other nuanced influencing factors that impact user perceptions of agents. 

Depending on the \textbf{type of conversation} user is having with agents, it may lead to differences in perceptions for similar conversational architecture elements. Cox et al. \cite{cox2022does}\cmt{[27]} found that the perceived competence and appropriateness of tone of different language formality styles depend on the sensitivity of information discussed in the conversation. In this particular study, a formal language style is preferred in medical history discussions as it is matching to the expectation of users, but there is no difference in perception between formal and casual styles when discussing income level and credit scores. In Jeong et al's study \cite{jeong2019exploring}\cmt{[10]}, users found the agent using fillers less intelligent and likable in a task-oriented conversation, but found the same agent using fillers as slight more intelligent and likable in a social-oriented conversation. Another factor that could impact perceptions is the \textbf{anonymity} of conversation. Based on user feedback, Lee et al. \cite{lee2020hear}\cmt{[23]} found that the anonymity of a conversational agent is a driving factor encouraging people to self disclose without having to worried about judgements from the CA. The perception of the agent may be different if the user's identity is not anonymous.

Other than the type of conversation, \textbf{user's characteristics} can also be influencing factors on their perception of agents. For example, the effect of matching user's conversational style on perception of agents depend on user's own conversational style, as participants with high consideration conversational style rated the lexically aligned agent as more trustworthy \cite{hoegen2019end}\cmt{[31]}. In the study by Cox et al. \cite{cox2022does}\cmt{[27]}, participants with lower levels of privacy concerns as well as those who believe in robotic intelligence found the chatbot more enjoyable, warm, competent and appropriate. Similarly, participants with positive attitudes towards computers were significantly more likely to indicate that the usage of fillers by agents was a positive aspect of the conversation, compared to participants with neutral attitudes towards computers \cite{pfeifer2009should}\cmt{[12]}. Lastly, user's prior experience with conversational agents could impact perception of agents. Experienced users perceived the agent with a response delay as lower in social presence compared to the one without delay, as it is seen as inefficient to wait for the CA to respond. However, novice users perceived higher social presence conversing with the CAs using response delays as it is more similar to conversations with human partners \cite{gnewuch2018faster}\cmt{[19]}.

%* Format: Response delay - Novice users perceived the agent as more socially present, but experienced users had a negative effect \cite{gnewuch2022opposing}\cmt{[20]}
%* Content: Humour - no overall significant difference between conventional method vs. agent using humour for enjoyment. Specifically, men enjoyed the agent's jokes more than women.  \cite{miyamoto2017improving}\cmt{[46]}.
%* Format: Proactivity - significant interaction between proactive dialogue strategies and task difficulty for perceived competence and perceived reliability. For easier tasks, system help is not really required. \cite{kraus2020effects}\cmt{[64]}
%* Preference for the level of social talk depended on the task, even within the same transactional context, as users preferred high level for playing a song, but low level for writing a text. \cite{volkel2021manipulating}\cmt{[68]}
%* Correlation between user's personality of agreeableness vs. preference for agreeable level of chatbot \cite{volkel2021examining}\cmt{[69]}
%* For expertise, multilingual students rated higher the non-native English-speaking virtual human. \cite{feijoo2021effects}\cmt{[70]}
%* Participants felt irritated when humorous statements were made when they talked about experiencing sadness \cite{go2021conversational}\cmt{[80]}

%\subsubsection{Study Design}

%\textbf{Interview vs experiment}
%* Humour - what's said vs. study results

%\textbf{Observer study vs. interaction study}
%* In observer study, participants attributed higher integrity (trustworthiness), response accuracy and likeability to the agent with lexical alignment, but this effect was not observed in the interaction study. Also, interaction study had lower cognitive demand but no effect in the observer study. \cite{linnemann2018can}\cmt{[15]}
%* \cite{zhu2022effects}\cmt{[26]}
%* \cite{cox2022does}\cmt{[27]}

\subsubsection{Relationship between perceptions}

Response delay: social presence has a significant effect on intention to use. 
\cite{gnewuch2022opposing}\cmt{[20]}

Perceived intelligence positively associated with perceived usefulness, perceived ease of use, initial trust, and perceived anthropomorphism. Perceived anthropomorphism is associated with perceived enjoyment, and intention to adopt. Perceived usefulness and perceived enjoyment impacts intention to adopt. \cite{moussawi2021perceptions}\cmt{[36]}

The size of the effect for language we observed is clearly higher than the size of the effect for voice. \cite{habler2019effects}\cmt{[63]}

VA self-repair can backfire if time or accuracy is of the essence. (repair and accuracy) \cite{cuadra2021my}\cmt{[67]}

\subsection{Ethical Considerations}

Self-disclosure encourage higher trust and intimacy, to disclose sensitive information. Who have access to this data? need to be aware of privacy / data sharing practices. \cite{lee2020hear}\cmt{[23]}

Evidence for the influence of voice gender and pitch on stereotypical trait attribution. Active trait attribution is missing as most participants attributes to the negative side of traits for CAs. \cite{tolmeijer2021female}\cmt{[62]}

The social and emotional benefits of self-repair in interaction need to be balanced against the creepiness of the monitoring and modelling needed to make self-repair possible. \cite{cuadra2021my}\cmt{[67]}


\subsection{Limitations and Future Work}

\subsubsection{Assumptions in designed personalities of CAs}
Sometimes a study is covering multiple conversational element cues, hard to break it out. For example, extroverted personality used in \cite{volkel2022user}\cmt{[75]} has emoticons, affective language, talkative, and self-disclosure. Need to break it down.

Also, breaking down "personalities" to its core components.

There are a few studies that designed conversational agents composed with multiple conversation architecture elements. This is especially evident in studies comparing different personalities of CAs, such as extroverted vs. introverted. In Volkel et al's study, the personality of extraversion is a combination of linguistic content like social ta

\cite{moilanen2022measuring}\cmt{[82]}\cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2021manipulating}\cmt{[68]}\cite{volkel2022user}\cmt{[75]}.







%Research challenges and opportunities

%Ethical considerations



\subsubsection{Gaps}

Combined effects
* integrated mental model \cite{knijnenburg2016inferring}\cmt{[34]}
* Anthropomorphized chatbot (text) using affective language (emotional expressions), self-referencing, emoticons, response delays. Resulted in higher perceived anthropomorphism, which in result led to lower negative word of mouth and loss of trust. anthropomorphic design is beneficial not only to initial trust but also to the ongoing trust relationship \cite{seeger2021chatbots}\cmt{[35]}

Lack of investigations - name a few areas

%\subsubsection{Human-human vs. Human-machine}

%* Impact of lexical alignment on people's perceived annoyance and likability differed in HHI (higher) and HCI (no impact). \cite{huiyang2022improving}\cmt{[17]}.


\section{Conclusions}

TBD


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
To Robert, for the bagels and explaining CMYK and color spaces.
\end{acks}






%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\onecolumn
\section{Appendix}

\begin{table*}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}lllc@{}}
\toprule
\textbf{Category} & \textbf{Theme}   & \textbf{Sample Codes}                                  & \textbf{No. Papers}   \\ \midrule
\multirow{3}{*}{Perception of Interaction with Agent}    & Usability       & accuracy, ease of use, efficiency, helpfulness & 23 \\
 & Engagement         & enjoyment, annoyance, desirable, intention to use  & 28         \\
 & Satisfaction       & service satisfaction, quality of interaction       & 12         \\ \midrule
\multirow{3}{*}{Perception of Agent's Ability}              & Intelligence    & knowledgeable, intelligent, expertise                             & 11 \\
 & Competence         & competent, capable                                 & 4          \\
 & Trust              & credibility, trustworthy, truthfulness, confidence & 15         \\ \midrule
\multirow{3}{*}{Perception of Social Connection with Agent}  & Conversation Tone  & appropriate, expressive, empathetic, persuasive    & 13 \\
 & Social Presence & connectedness, familiarity, similarity, psychological distance    & 18        \\
 & Intimacy           & intimate, rapport, quality of relationship         & 7          \\ \midrule
\multirow{2}{*}{Perception of Agent's Humanness}            & Human-likeness  & human-like, natural, artificial, machine-like                     & 20 \\
 & Personality Traits & friendly, kind, warm, creepy, likeable, polite     & 27         \\ \bottomrule
\end{tabular}%
}
\caption{Perception measures}
\label{tab:appendix-perceptions}
\end{table*}



\begin{table*}[h]
\resizebox{\textwidth}{!}{
\begin{tabular}{@{}p{0.2\linewidth} | p{0.2\linewidth} | p{0.2\linewidth}@{}}
\toprule
 \textbf{Category} & \textbf{Theme} & \textbf{Papers} \\ \midrule
\multirow{4}{*}{Linguistic Content}    
    & Affective Language 
    &  
\\
     & Social Talk
    &
\\
    & Humour
    &
\\
    & Agent-Initiated Content
    &
\\ \midrule
\multirow{4}{*}{Linguistic Style}
    & Formality
    &
\\
    & Alignment 
    &
\\
    & Elaborateness
    &
\\
    & Disfluency
    &
\\ \midrule
\multirow{2}{*}{Non-Linguistic Format}
    & Prosodic Cue
    &
\\
    & Text Variation
    &
\\ \bottomrule 
\end{tabular}%
}
\caption{Conversation architecture elements}
\label{tab:appendix-cues}
\end{table*}

\end{document}
\endinput
%%
%% End of file `paper.tex'.


\multirow{3}{*}{Perception of Interaction with Agent}    & Usability       \\
 & Engagement                  \\
 & Satisfaction                \\ \midrule
\multirow{3}{*}{Perception of Agent's Ability}              & Intelligence     \\
 & Competence                  \\
 & Trust                       \\ \midrule
\multirow{3}{*}{Perception of Social Connection with Agent}  & Conversation Tone  \\
 & Social Presence         \\
 & Intimacy                    \\ \midrule
\multirow{2}{*}{Perception of Agent's Humanness}            & Human-likeness   \\
 & Personality Traits          \\ \bottomrule