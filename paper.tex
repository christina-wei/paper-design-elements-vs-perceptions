%% Manuscript for the effect of designed conversational architecture on the perception of agents
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,screen,review, anonymous]{acmart}

\usepackage[linewidth=1pt]{mdframed}
\usepackage{lipsum}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{makecell} 

\newcommand{\cmt}[1]{}%{\ignorespaces}


%% NOTE that a single column version may be required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2023}
\acmYear{2023}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation email}{June 03--05,
  2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}
%TC:ignore

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
% \title[short title]{How to Make Pinocchio a Real Boy? Designing conversational architecture elements to achieve desirable anthropomorphized perceptions}
\title{The Bot on Speaking Terms: The Effects of Conversation Architecture on Perceptions of Conversational Agents}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Christina Wei}
\email{christina.wei@mail.utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \country{Canada}
}

\author{Young-Ho Kim}
\email{ygho.kim@navercorp.com}
\affiliation{%
  \institution{Naver Corporation}
  \city{Seoul}
  \country{Korea}
}

\author{Anastasia Kuzminykh}
\email{anastasia.kuzminykh@utoronto.ca}
\affiliation{%
  \institution{University of Toronto}
  \city{Toronto}
  \country{Canada}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Wei, Kim, Kuzminykh} %It will be automatically anonymized through the document class property anonymous

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
%Conversational agents employ natural language to interact with human users. While it is broadly accepted that the specifics of speech interactions affect the perception of communicating parties, 
%Previous research has demonstrated a relationship between the structure of conversational agents' natural language interaction and how these agents are perceived by their users. However, 
%there is a lack of systematic understanding of the connections between the perception of agents and elements of conversation architecture. % are not well understood. 
%Furthermore, there is no clear definition of the aspects of perception that are affected and the elements of conversation architecture. In this paper, we present a synthesized framework demonstrating the connections between perceptions of agents and conversation architecture elements, using a taxonomy of eleven perceptions grouped into four categories, and ten elements grouped into three categories. We highlight the need for further research for the perception of agent's ability and perception of social connection with agent's, especially as it relates to the linguistic style of conversational agents.  Also, there is the need to be consistent in the assessment of agents' perceptions, and consider ethical concerns in design.
%[AK Edit] Conversational agents are deliberately designed to interact by simulating natural conversation, and the effectiveness of these interactions is shown to be affected by users' perceptions of an agent. While research on human-human and human-agent communication suggests the association between speech specifics and perceptions of communicating parties, there is a lack of systematic understanding of how an agent’s conversation architecture affects users' perceptions. To address this gap, we present a framework that outlines the relationships between elements of agents’ conversation architecture grouped around dialog strategy, content affectiveness, content style and speech format, and agent characteristics grouped around perceptions of interactions with an agent, agent's ability, sociability, and humanness. Synthesized based on literature review (n=57), the framework demonstrates both the identified relationships and the areas lacking empirical evidence. We discuss the implications of the framework for the conversation design and highlight the inconsistency issues with the domain terminology and measurements.
Conversational agents mimic natural conversation to interact with users. Since the effectiveness of interactions strongly depends on users’ perception of agents, it is crucial to design agents’ behaviors to provide the intended user perceptions. Research on human-agent and human-human communication suggests that speech specifics are associated with perceptions of communicating parties, but there is a lack of systematic understanding of how speech specifics of agents affect users' perceptions. To address this gap, we present a framework outlining the relationships between elements of agents’ conversation architecture (dialog strategy, content affectiveness, content style and speech format) and aspects of users’ perception (interaction, ability, sociability and humanness). Synthesized based on literature reviewed from the domains of HCI, NLP and linguistics (n=57), this framework demonstrates both the identified relationships and the areas lacking empirical evidence. We discuss the implications of the framework for conversation design and highlight the inconsistencies with terminology and measurements.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%\begin{CCSXML}
%<ccs2012>
% <concept>
%  <concept_id>10010520.10010553.10010562</concept_id>
%  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%  <concept_significance>500</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010575.10010755</concept_id>
%  <concept_desc>Computer systems organization~Redundancy</concept_desc>
%  <concept_significance>300</concept_significance>
% </concept>
% <concept>
%  <concept_id>10010520.10010553.10010554</concept_id>
%  <concept_desc>Computer systems organization~Robotics</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
% <concept>
%  <concept_id>10003033.10003083.10003095</concept_id>
%  <concept_desc>Networks~Network reliability</concept_desc>
%  <concept_significance>100</concept_significance>
% </concept>
%</ccs2012>
%\end{CCSXML}

%\ccsdesc[500]{Computer systems organization~Embedded systems}
%\ccsdesc[300]{Computer systems organization~Redundancy}
%\ccsdesc{Computer systems organization~Robotics}
%\ccsdesc[100]{Networks~Network reliability}

\ccsdesc{TBD}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{conversational agents, user perception, conversational architecture, anthropomorphized perceptions}

%%\received{20 February 2007}
%%\received[revised]{12 March 2009}
%%\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
%TC:endignore


\section{Introduction}

Conversational agents (CAs), such as Amazon Alexa or Siri, are designed to interact with humans using natural language through voice or text modalities. %Adoption of CAs such as Amazon Alexa or Siri (Apple) is rapidly growing in the market, with half of Internet users in United States owning one or more smart speaker devices \cite{2022comscore}. These conversational agents are designed to be ubiquitous, easily accessible through smartphones, tablets, laptops and smart devices. Since these agents interact with users using natural language, there are nuances in their communications affected by conversation architecture, which is what they say and how they say it.
%they solicit social responses from users, encouraging users to attribute lifelike qualities, a.k.a. anthropomorphized perceptions to CAs \cite{eyssel2012if}.
%Anthropomorphism is defined as the attribution of traits that we typically associate with being distinctly human to nonhuman entities \cite{waytz2010sees}. For example, users tend to personify conversational agents like Amazon Alexa by using person pronouns instead of object pronouns in online reviews \cite{purington2017alexa}.  Research shows that anthropomorphic design is beneficial to establishing and maintaining trust between users and conversational agents \cite{seeger2021chatbots}. Also, speakers tend to align their lexical choices with conversational agents, similar to human-human conversations \cite{cowan2015does}. Anthropomorphism has been shown to ease user interactions, e.g. making agents more approachable, engaging, and trustworthy when they exhibit human characteristics \cite{qiu2009evaluating}. These processes are of particular interest for human-agent communication because they form the basis for user expectations and predispositions regarding agents' behavior, reliability of the information, etc. \cite{kuzminykh2020genie}.
Previous research has shown that there is a connection between conversation architecture and the perception of agents. Studies have found that conversational agents are perceived as more socially present and emotionally intelligent if they use affect language such as sentiment-adaptive response based on user's utterances, resulting in higher user satisfaction \cite{diederich2019emulating}\cite{yang2017perceived}. Also, CAs that mimic user's utterances through lexical alignment reduce users' cognitive workload, resulting in higher engagement with the interaction \cite{spillner2021talk}. Non-linguistic cues such as expressive prosody contribute to higher perceived intimacy with the user, as well as higher perceived enjoyment and ease of use \cite{kim2020can}. Although research on how conversation architecture affects agents' perceptions already exists, there is a lack of understanding on the coverage of relationships explored in literature, as well as synthesizing these findings into a generalized framework. One of the possible issues is the lack of clear and consistent definition on the aspects of user's perceptions of agent and conversation architectural elements.
%However, conversational architecture design may lead to negative consequences, such as an agent with an extroverted personality may be seen as less trustworthy, as users are irritated by the system's overly familiar attitude \cite{andrews2012system}.

Related to the perception aspects of agents, there have been recent efforts to systematically analyze user experience criteria used to evaluate conversational agents. Some review papers have created a list of dimensions used to assess conversational agents, which include the perceptions of agents (e.g. empathy, humanness) alongside other assessments (e.g. physiological data) \cite{clark2019state}\cite{finch2020towards}.
%In Clark et al's review for the state of speech interfaces, the authors created a list the different concepts used to assess disembodied voice-based agents such as user attitudes and task performance \cite{clark2019state}. 
Other papers categorized CA assessments into themes. For example, Rapp et al. \cite{rapp2021human} generated themes related to how users' experience with chatbots such as experiencing the chatbot including assessments on expectation, perception, satisfaction etc. Most recently, Zheng et al's literature review on the UX research of CAs \cite{zheng2022ux} categorized the metrics based on the type of method used, including technical measures like system error rate and perception measures like perceived social presence. However, existing studies use different terminologies and categories across aspects of perception. As an illustration, it is unclear if the theme of experiencing the chatbot from Rapp et al. \cite{rapp2021human} contains similar aspects to the perception towards CA in Zheng et al \cite{zheng2022ux}'s analysis.

For conversation architecture elements, Feine et al \cite{feine2019taxonomy} created foundational knowledge by providing a taxonomy of social cues, which is defined as "a cue of a CA that triggers a social reaction of the user towards the CA." Elements of conversation architecture are captured in the taxonomy, alongside other social cues such as the embodied agents' appearance and movements. Clark et al \cite{clark2019state} had also captured conversation architecture elements under the research topic of system speech production, with similar categorizations across content, style, and other topics. While these papers captured conversation architecture elements as part of their broader scope of research, there exist the need for standardized definitions specifically for conversation architecture that reflects its unique characteristics.

%there is existing research to systematically analyze them, like Feine et al \cite{feine2019taxonomy}'s overall framework provides consistent categories for social cues. However, it is unknown which conversation architecture elements have impacts on the perceptions of agents. Lastly, while there are various studies investigating the effect of  conversational architecture elements on the anthropomorphized perception of agents, we did not find any systematic review and analysis to generalize the findings into a usable framework.

In this paper, we are addressing these research gaps by analyzing how to design conversation architecture in order to orchestrate the perceptions of conversational agents. First, we want to understand \textbf{(RQ1) what perception aspects of agents are being explored in relation to the effects of conversation architecture elements}. Various elements of conversation architecture can be used in a CA's utterances such as humour, emoticons, or lexical alignment. This leads to our second research question: \textbf{(RQ2) what elements of conversation architecture are relevant to the perceptions of agents?} Lastly, we want to understand the impact of conversation architecture on perceptions of agent, which leads to our third research question: \textbf{(RQ3) what are the relationships between the specifics of conversation architecture elements and the perceptions of CAs?}

To answer these questions, we performed a comprehensive review of existing literature from 2010 to 2022 and synthesized findings on the impact of conversation architecture elements on the perceptions of CAs based on relevant papers (n=57). We collected perceptions of agents that are affected by conversation architecture,  grouped the aspects into four categories and eleven sub-categories (Table \ref{tab:perceptions}). We also analyzed conversation architecture related to perception of agents and grouped them into three categories and ten elements (Table \ref{tab:cues}). Lastly, we coded the explored connections between conversation architecture and perceptions and demonstrated the relationship into a synthesized framework (Figure \ref{fig:heatmap-impact}). Through our analysis, we also found that there are inconsistencies in the assessment of perceptions across studies, as well as influencing factors other than conversation architecture that impact the perceptions of agents.

This work contributes to the HCI community by presenting an in-depth analysis on the affect of conversation architecture on perceptions of conversational agents. We created a taxonomy for perception aspects and conversation architecture elements, providing clear and consistent terms that can be used in future research. Also, our analysis extends existing reviews on UX research of CAs \cite{clark2019state}\cite{rapp2021human}\cite{zheng2022ux} by providing a synthesized framework outlining the relationships between conversation architecture and perceptions of agents. With the help of this framework, we are taking the first step to understand how to design conversational agents to solicit specific social reactions from users.

In the remainder of the paper, we first outline our data collection and data analysis process, as well as the characteristics of the papers in our reviewed corpus. Following that, we describe in detail the taxonomy for the perception of agents, the taxonomy for conversation architecture element, as well as the framework on the relationships between perceptions of agents and conversation architecture. Finally, we discuss research challenges and opportunities as well as ethical considerations for designing conversational architecture to orchestrate perceptions of conversational agents.


%\section{Literature Review}

%\cite{finch2020towards} Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols


\section{Methods}

This section describes the research methodologies used for data collection and data analysis. Additionally, it presents the characteristics of the papers in our reviewed corpus.

\subsection{Data Collection}

Following PRISMA guidelines \cite{prisma}, we reviewed and selected literature exploring the relationship between the specifics of conversation architecture elements and perceptions of CAs. Searches were carried out in the ACM Digital Library between January 1 and January 15, 2023. Through our analysis, we didn't find any common terms used to refer to either conversation architecture elements, or aspects of perceptions. As such, we kept our search term to capture articles related to conversational agents. Based on search terms used in previously published literature reviews \cite{clark2019state}\cite{rapp2021human}, the following keywords are used to search for publications related to conversational user interfaces:
\newline

\textit{"conversational agent" OR "natural language interface" OR "IPA" OR "intelligent personal assistant" OR "chatbot" OR "speech interface" OR "voice assistant" OR "intelligent agent" OR "human-chatbot communication" OR "virtual agent" OR "dialog* system" OR "voice user interface" OR "human computer dialog*"}
\newline

The following selection criteria are applied to identify literature related to the effect of conversational architecture on the perception of agents:
\begin{itemize}
  \item The paper was published between 2010 and 2022.
  \item The paper is peer-reviewed and written in English.
  \item The paper contains the use of voice-based or text-based conversational agents.
  \item The paper contains studies on the impact of conversation architecture elements on the perceptions of agents.
  \item The paper contains impact of conversation architecture elements can be separated from other effects (e.g. embodiment).

\end{itemize}

The initial query retrieved 2901 unique publications. We screened the titles and abstracts of the papers based on the selection criteria above, resulting in 221 papers. The fully body of these papers are then reviewed, selecting papers that met the criteria. A search for additional literature was also performed to supplement the corpus, adding 8 more papers to the selection. In total, we identified 57 relevant articles for analysis (see Figure \ref{fig:prisma}).

\begin{figure}[h]
  \centering
  \includegraphics[width=1\columnwidth]{fig-prisma.png}
  \caption{Literature search using PRISMA guidelines}
  \label{fig:prisma}
\end{figure}

\subsubsection*{Literature Corpus Characteristics}

The papers reviewed (n=57) were published between May 2011 and November 2022. More than 75\% of the papers were published in or after 2019, with a slight trend upwards over the years (see Figure \ref{fig:paper}). The vast majority of the papers in our corpus were published in conference proceedings (n=50), with the remainder papers published in journals. Out of the papers published in conferences, the top conferences were The ACM Conference on Human Factors in Computing Systems\footnote{https://dl.acm.org/conference/chi} (n=16), Conversational User Interfaces\footnote{https://dl.acm.org/conference/cui} (n=7), Human-Agent Interaction\footnote{https://dl.acm.org/conference/hai} (n=4), and Intelligent Virtual Agents\footnote{https://dl.acm.org/conference/iva} (n=4). 
%Out of the papers published in journals, some venues include the International Journal of Human-Computer Interaction\footnote{https://www.tandfonline.com/journals/hihc20} (n=2) and Interacting with Computers\footnote{https://academic.oup.com/iwc} (n=1).

On the modality characteristics of the conversational agents in the corpus, there is a roughly even split between the modalities, with slightly more papers exploring voice-based CAs (n=30) compared to text-based CAs (n=27).

\begin{figure}[h]
  \centering
  \includegraphics[width=\columnwidth]{fig-paper.png}
  \caption{Number of papers by year}
  \label{fig:paper}
\end{figure}

\subsection{Data Analysis}

\subsubsection*{Perceptions of Agents} To understand the perceptions of agents related to conversation architecture (RQ1), assessments for the perceptions of agents were extracted from each paper. We used inductive thematic analysis to group these assessments into codes based on their meanings. For example, the code likeability of the agent contains the questionnaire item "this voice agent was likeable" used by \cite{cuadra2021my}\cmt{[67]}, Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed}'s set of questions on likeability used by \cite{linnemann2018can}\cmt{[15]}, and Subjective Assessment of Speech System Interface (SASSI) questionnaire \cite{hone2000towards}\cmt{sassi}'s set of questions on likeability used by \cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}. This step resulted in 83 unique codes. These codes are then organized based similarity of the meanings, resulting in 11 aspects of perceptions. For example, the aspect of personality traits of the agent contains measurements such as likeability, funniness, and kindness. Lastly, the 11 aspects are grouped into 4 categories: perception of interaction with agent, perception of agent's ability, perception of sociability with agent, and perception of agent's humanness (Table \ref{tab:perceptions}).

\subsubsection*{Conversation Architecture Elements}
As to the elements of conversation architecture that are relevant to the perception of agents (RQ2), we extracted the specifics of conversation architecture used in each paper. Some of the papers used multiple features in their CA design, such as the the anthropomorphic agent used in Seeger et al's study \cite{seeger2021chatbots}\cmt{[35]}. In these composite situations, we broke them down into their individual features. For example, the anthropomorphic agent \cite{seeger2021chatbots}\cmt{[35]} was separated into emotional expressions, is-typing indicator, emoticons, and response delay and captured as codes. 58 unique codes were created as part of this process, capturing features like sentiment-adaptive responses \cite{diederich2019emulating}\cmt{[25]}, lexical alignment \cite{spillner2021talk}\cmt{[18]}, and typos \cite{westerman2019believe}\cmt{[9]}. We then organized these codes into elements based on similarity, resulting in 12 elements of conversation architecture. For example, the element of disfluency contains fillers \cite{jeong2019exploring}\cmt{[10]}\cite{wester2015artificial}\cmt{[14]}, interjections \cite{ceha2022expressive}\cmt{[77]}\cite{hu2021enhancing}\cmt{[56]}, repetitions \cite{yang2021effect}\cmt{[72]} and typos \cite{westerman2019believe}\cmt{[9]}. These elements are grouped into 4 categories: dialog strategy, content affectiveness, content style, and speech format (Table \ref{tab:cues}).

\subsubsection*{Relationship Between Perceptions of Agents and Conversation Architecture}
To study the effect of conversation architecture on users' perceptions (RQ3), we extracted the connections explored in each paper, using the perception aspects and conversation architecture elements developed in the previous data analysis steps. Each connection's effect was also recorded based on whether an association was found in the study and the nature of that association. Out of our review corpus, 265 connections between perceptions of agents and conversation architecture were explored in literature. To analyze the specifics of conversation architecture that affect the perceptions of CAs, 72 connections that did not result in observed relationships were discarded, resulting in 193 relationships for analysis. For example, the connection between the matching style of a CA and user satisfaction was removed because Hoegen et al. \cite{hoegen2019end}\cmt{[31]} did not find a significant difference between the style matching agent and the non-style matching agent for overall interaction satisfaction. Out of the 193 relationships, 10 were relationships based on agents using multiple architecture elements (e.g. \cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2021manipulating}\cmt{[68]}). They were not included in the final framework as we could not attribute the perceptions of agents to the underlying core elements. Overall, 183 relationships between individual architecture elements and perceptions of agents are incorporated into our synthesized framework, visualized as a heatmap to demonstrate their relationships with each other (Figure \ref{fig:heatmap-impact}).

\section{Findings}

\begin{figure*}[]
  \centering
  \includegraphics[width=\textwidth]{fig-heatmap-impact.png}
  \caption{Heatmap of literature for perception of conversational agents for each type of conversational architecture element}
  \label{fig:heatmap-impact}
\end{figure*}

\subsection{Perceptions of Agents}

As shown in Table \ref{tab:perceptions}, there are four categories defined for the perceptions of conversational agents covering 11 different aspects of perception. The details of each category and aspect are discussed below.

\textbf{Perception of interaction with agent} assesses the overall interaction quality users had with the conversational agent. The three aspects for this perceptions are usability, engagement and satisfaction. \textit{Usability} captures the utilitarian component of the interaction, whether it was accurate, easy to use, efficient or helpful. Some commonly used methods to evaluate usability include the response accuracy portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, or the NASA Task Load Index (NASA-TLX) \cite{hart1988development}\cmt{nasa} for cognitive workload. Questions such as "the system is easy to use" or "it is easy to understand the agent" are also used to evaluate usability. \textit{Engagement} on the other hand captures users' emotional reactions to the CA, whether they have enjoyed the conversation, or annoyed or frustrated with the interaction. Some commonly used methods to evaluate engagement include the annoyance portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, and the Use Engagement Scale (UES) \cite{o2018practical}\cmt{ues}. Questions such as "I enjoyed using the system" or "I felt frustrated with the agent" are also used to evaluate engagement. Lastly, \textit{Satisfaction} captures users' overall satisfaction interacting with the agent. Questions such as "the overall assessment of conversing with the CA was satisfactory" are used to evaluate this perception.

\textbf{Perception of agent's ability} assesses the perceived capabilities of the agent. Unlike system capabilities that affect agent's performance, the perceived ability category captures perceptions of agents with equivalent system capabilities but varied conversation architecture elements. Specifically, \textit{intelligence} captures the agent's expertise and knowledge, and it is commonly administered through the Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} using the set of questions related to perceived intelligence. Also survey questions such as asking users about the agent's intelligence and domain knowledge are used to evaluate perceived intelligence. \textit{Competence} takes intelligence one step further by examining the agent's ability to put its intelligence into practice. Surveys or qualitative feedback are usually used to assess if the agent is capable and competent, and whether users have confidence in the agent's ability to get the job done. Lastly, \textit{credibility} captures agent's truthfulness, benevolence, and user's confidence in CAs. Some commonly used methods to evaluate trust include the Trust Propensity Scale \cite{mayer1999effect} and the Individualized Trust Scale (ITS) \cite{wheeless1977measurement}. Questions such as "is the agent honest" and "can I trust the agent with sensitive information" are also used to evaluate trust.

\textbf{Perception of the sociability with agent} assesses the emotional connections that users have with agents. This category includes perception aspects of conversation tone, social presence and intimacy. \textit{Conversation tone} captures the affective impression of the agent's tone, such as empathy and expressiveness. Also, this aspect includes whether the tone used by the agent was perceived as friendly, polite or warm. \textit{Social presence} captures the sense of connectness and psychological distance users have with an agent. Some aspects in this category include the sense of familiarity or similarity with the agent, and whether users feel the agent behaves like them or have similar attitudes to them. The category of \textit{Intimacy} extends social presence into the realm of the quality of relationships with an agent. Some commonly used methods to assess intimacy include the set of social attraction questions from the interpersonal attraction questionnaire \cite{mccroskey1975development} and the quality of relationship inventory (QRI) \cite{pierce1997assessing}. These questionnaires include questions like "I think the agent could be a friend of mine", or "I feel we could establish a personal relationship with each other".

\textbf{Perception of agent's humanness} assesses the specifics of anthropomorphized perceptions of conversational agents. \textit{Human-likeness} captures whether the agent presented itself as natural and human-like, or artificial and machine-like. The Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} set of questions related to anthropomorphism and the Ascent of Man scale \cite{kteily2015ascent} are commonly used methods to evaluate human-likeness. Survey questions with semantic scales such as "human-like / machine-like" and "artificial / natural" are also commonly used for this aspect of perception. \textit{Personality traits} captures the human characteristics that are attributes to the agent. This is commonly collected as qualitative feedback from users, commenting on whether the agent is extroverted or introverted, or the perceived personality such as likeable, funny or witty. Sometimes the Big-5 personality traits questionnaire \cite{gosling2003very} is used to map an agent's disposition on various personality dimensions.

Overall there is a good coverage of different aspects of perception based on the list of papers reviewed in our corpus. The most commonly explored aspect categories is the perception the interaction with agent, followed by the perception of agent's humanness. There are two aspects that are the least explored compared to the others relationships: competence within the perception of agent's ability, and intimacy within the perception of social connection with agent. This may be due to the controlled lab settings for the experiments, where participants are given the scenarios for interaction. This type of environment is not conducive to forming relationships with a conversational partner, as noted by Linnerman et al. in their discussions \cite{linnemann2018can}\cmt{[15]}. The same factor could impact the assessment of agent's competence, as the users may not feel like they have the expertise to assess their perceptions. 
%These factors could contribute to the reasons why competency and intimacy are not as frequently measured in experimental studies.

\begin{table*}[ht]
\renewcommand*{\arraystretch}{1.4}
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}p{0.17\textwidth} | p{0.12\textwidth} | p{0.20\textwidth} | >{\centering}p{0.09\textwidth} | p{0.42\textwidth} @{}}
%!{\vrule width 1.2pt} 
\Xhline{1.2pt}
\multicolumn{2}{l|}{\textbf{Perception Aspects}} & \textbf{Examples} & \textbf{No. Papers} & \textbf{Papers} 
\\ \Xhline{1.2pt}
\multirow{3}{*}{\parbox{0.17\textwidth}{Perception of \newline Interaction with Agent}}
    & Usability & accuracy, ease of use, \newline efficiency, helpfulness & 23 
    & \cite{ashktorab2019resilient}\cmt{[88]}\cite{ceha2022expressive}\cmt{[77]}\cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}\cite{cuadra2021my}\cmt{[67]}\cite{dubiel2020persuasive}\cmt{[60]}\cite{elsholz2019exploring}\cmt{[61]}\cite{haas2022keep}\cmt{[78]}\cite{habler2019effects}\cmt{[63]}\cite{healey2013relating}\cmt{[39]}\cite{hu2022polite}\cmt{[76]}\cite{huiyang2022improving}\cmt{[17]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2019comparing}\cmt{[89]}\cite{kim2020can}\cmt{[24]}
    \cite{kraus2020effects}\cmt{[64]}\cite{linnemann2018can}\cmt{[15]}\cite{ma2022ask}\cmt{[29]}\cite{miehle2018exploring}\cmt{[51]}\cite{misu2011toward}\cmt{[83]}\cite{roy2021users}\cmt{[71]}\cite{spillner2021talk}\cmt{[18]}\cite{wilhelm2022keep}\cmt{[28]}
\\ \cline{2-5}
    & Engagement & enjoyment, annoyance, \newline desirable, intention to use  & 28
    & \cite{andrews2012system}\cmt{[38]}\cite{ceha2022expressive}\cmt{[77]}\cite{ceha2021can}\cmt{[57]}\cite{chan2021kinvoices}\cmt{[74]}\cite{cox2022does}\cmt{[27]}\cite{cuadra2021my}\cmt{[67]}\cite{elsholz2019exploring}\cmt{[61]}\cite{fadhil2018effect}\cmt{[52]}\cite{gnewuch2022opposing}\cmt{[20]}\cite{go2021conversational}\cmt{[80]}\cite{healey2013relating}\cmt{[39]}\cite{huiyang2022improving}\cmt{[17]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2020can}\cmt{[24]}\cite{kim2019comparing}\cmt{[89]}
    \cite{lee2020hear}\cmt{[23]}\cite{linnemann2018can}\cmt{[15]}\cite{ma2022ask}\cmt{[29]}\cite{miehle2018exploring}\cmt{[51]}\cite{miyamoto2017improving}\cmt{[46]}\cite{moilanen2022measuring}\cmt{[82]}\cite{roy2021users}\cmt{[71]}\cite{spillner2021talk}\cmt{[18]}\cite{volkel2021examining}\cmt{[69]}\cite{volkel2022user}\cmt{[75]}\cite{xiao2021let}\cmt{[73]}\cite{yang2021effect}\cmt{[72]}\cite{zhu2022effects}\cmt{[26]}    
\\ \cline{2-5}
    & Satisfaction & service satisfaction, quality of interaction & 12
    & \cite{ceha2022expressive}\cmt{[77]}\cite{choi2020nobody}\cmt{[54]}\cite{diederich2019emulating}\cmt{[25]}\cite{elsholz2019exploring}\cmt{[61]}\cite{habler2019effects}\cmt{[63]}\cite{gnewuch2018faster}\cmt{[19]}\cite{hoegen2019end}\cmt{[31]}\cite{hu2022polite}\cmt{[76]}\cite{ma2022ask}\cmt{[29]}\cite{roy2021users}\cmt{[71]}\cite{wilhelm2022keep}\cmt{[28]}\cite{yang2017perceived}\cmt{[44]}
\\ \Xhline{1.2pt} 
\multirow{3}{*}{\parbox{0.16\textwidth}{Perception of Agent's Ability}}
    & Intelligence & knowledgeable, intelligent, expertise & 11
    & \cite{ashktorab2019resilient}\cmt{[88]}\cite{ceha2021can}\cmt{[57]}\cite{chan2021kinvoices}\cmt{[74]}\cite{cuadra2021my}\cmt{[67]}\cite{dubiel2020persuasive}\cmt{[60]}\cite{feijoo2021effects}\cmt{[70]}\cite{hu2021enhancing}\cmt{[56]}\cite{jeong2019exploring}\cmt{[10]}\cite{spillner2021talk}\cmt{[18]}\cite{volkel2022user}\cmt{[75]}\cite{yang2017perceived}\cmt{[44]} 
\\ \cline{2-5}
    & Competence & competent, appropriate & 6 
    & \cite{cox2022does}\cmt{[27]}\cite{kraus2020effects}\cmt{[64]}\cite{jestin2022effects}\cmt{[81]}\cite{lee2019s}\cmt{[55]}\cite{misu2011toward}\cmt{[83]}\cite{westerman2019believe}\cmt{[9]}
\\ \cline{2-5}
    & Trust & credibility, trustworthy, truthfulness, confidence & 15
    & \cite{andrews2012system}\cmt{[38]}\cite{chan2021kinvoices}\cmt{[74]}\cite{dubiel2020persuasive}\cmt{[60]}\cite{fadhil2018effect}\cmt{[52]}\cite{healey2013relating}\cmt{[39]}\cite{hoegen2019end}\cmt{[31]}\cite{huiyang2022improving}\cmt{[17]}\cite{jestin2022effects}\cmt{[81]}\cite{kraus2020effects}\cmt{[64]}\cite{lee2020hear}\cmt{[23]}\cite{linnemann2018can}\cmt{[15]}\cite{ma2022ask}\cmt{[29]}\cite{seeger2021chatbots}\cmt{[35]}\cite{tolmeijer2021female}\cmt{[62]}\cite{wilhelm2022keep}\cmt{[28]}    
\\ \Xhline{1.2pt} 
\multirow{3}{*}{\parbox{0.16\textwidth}{Perception of \newline Sociability with Agent}}
    & Conversation Tone & friendly, warm, empathetic, persuasive & 20 
    & \cite{ashktorab2019resilient}\cmt{[88]}\cite{chan2021kinvoices}\cmt{[74]}\cite{cox2022does}\cmt{[27]}\cite{cuadra2021my}\cmt{[67]}\cite{daher2020empathic}\cmt{[58]}\cite{diederich2019emulating}\cmt{[25]}\cite{dubiel2020persuasive}\cmt{[60]}\cite{healey2013relating}\cmt{[39]}\cite{hu2021enhancing}\cmt{[56]}\cite{hu2022polite}\cmt{[76]}\cite{jestin2022effects}\cmt{[81]}\cite{khooshabeh2011does}\cmt{[37]}\cite{kim2019comparing}\cmt{[89]}\cite{lee2019s}\cmt{[55]}\cite{miehle2018exploring}\cmt{[51]}
    \cite{moilanen2022measuring}\cmt{[82]}\cite{tolmeijer2021female}\cmt{[62]}\cite{yang2021effect}\cmt{[72]}\cite{yang2017perceived}\cmt{[44]}\cite{zhu2022effects}\cmt{[26]}
\\ \cline{2-5}
    & Social Presence & connectedness, familiarity, psychological distance & 18
    & \cite{ceha2022expressive}\cmt{[77]}\cite{ceha2021can}\cmt{[57]}\cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}\cite{cuadra2021my}\cmt{[67]}\cite{diederich2019emulating}\cmt{[25]}\cite{gnewuch2018faster}\cmt{[19]}\cite{gnewuch2018chatbot}\cmt{[21]}\cite{gnewuch2022opposing}\cmt{[20]}\cite{go2021conversational}\cmt{[80]}\cite{khooshabeh2011does}\cmt{[37]}\cite{kim2020can}\cmt{[24]}\cite{lee2019s}\cmt{[55]}\cite{lubis2019positive}\cmt{[43]}\cite{lubold2016effects}\cmt{[86]}
    \cite{ma2022ask}\cmt{[29]}\cite{niewiadomski2013laugh}\cmt{[85]}\cite{westerman2019believe}\cmt{[9]}    
\\ \cline{2-5}
    & Intimacy & intimate, rapport, quality of relationship & 7 
    & \cite{choi2020nobody}\cmt{[54]}\cite{khooshabeh2011does}\cmt{[37]}\cite{kim2020can}\cmt{[24]}\cite{lee2020hear}\cmt{[23]}\cite{linnemann2018can}\cmt{[15]}\cite{lubold2016effects}\cmt{[86]}\cite{westerman2019believe}\cmt{[9]}
\\ \Xhline{1.2pt}
\multirow{2}{*}{\parbox{0.16\textwidth}{Perception of Agent's Humanness}}
    & Human-likeness & human-like, natural, \newline artificial, machine-like & 20
    & \cite{ashktorab2019resilient}\cmt{[88]}\cite{ceha2021can}\cmt{[57]}\cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}\cite{cox2022does}\cmt{[27]}\cite{diederich2019emulating}\cmt{[25]}\cite{gnewuch2018faster}\cmt{[19]}\cite{haas2022keep}\cmt{[78]}\cite{hu2022polite}\cmt{[76]}\cite{jeong2019exploring}\cmt{[10]}\cite{jestin2022effects}\cmt{[81]}\cite{lubis2019positive}\cmt{[43]}\cite{ma2022ask}\cmt{[29]}\cite{misu2011toward}\cmt{[83]}\cite{niewiadomski2013laugh}\cmt{[85]}
    \cite{ouchi2019should}\cmt{[59]}\cite{seeger2021chatbots}\cmt{[35]}\cite{wester2015artificial}\cmt{[14]}\cite{westerman2019believe}\cmt{[9]}\cite{zhu2022effects}\cmt{[26]}    
\\ \cline{2-5}
    & Personality Traits & likeable, kind, witty, funny, creepy & 20
    & \cite{andrews2012system}\cmt{[38]}\cite{ceha2022expressive}\cmt{[77]}\cite{ceha2021can}\cmt{[57]}\cite{chan2021kinvoices}\cmt{[74]}\cite{cuadra2021my}\cmt{[67]}\cite{haas2022keep}\cmt{[78]}\cite{habler2019effects}\cmt{[63]}\cite{healey2013relating}\cmt{[39]}\cite{hu2022polite}\cmt{[76]}\cite{huiyang2022improving}\cmt{[17]}\cite{jeong2019exploring}\cmt{[10]}\cite{kim2019comparing}\cmt{[89]}\cite{lee2020hear}\cmt{[23]}\cite{linnemann2018can}\cmt{[15]}\cite{miehle2018exploring}\cmt{[51]}
    \cite{ouchi2019should}\cmt{[59]}\cite{volkel2021manipulating}\cmt{[68]}\cite{volkel2022user}\cmt{[75]}\cite{wester2015artificial}\cmt{[14]}\cite{zhu2022effects}\cmt{[26]} 
\\ \Xhline{1.2pt}
\end{tabular}%
}
\caption{Perception measures}
\label{tab:perceptions}
\end{table*}

\begin{table*}[h]
\resizebox{\textwidth}{!}{
\renewcommand*{\arraystretch}{1.4}
\begin{tabular}{@{}p{0.17\textwidth} | p{0.14\textwidth} | p{0.25\textwidth} | >{\centering}p{0.09\textwidth} | p{0.34\textwidth} @{}}
\Xhline{1.2pt}
\multicolumn{2}{l|}{\textbf{Conversation Architecture Elements}} & \textbf{Examples} & \textbf{No. Papers} & \textbf{Papers}
\\ \Xhline{1.2pt}
\multirow{3}{*}{Dialog Strategy} & Social Dialog & social talk, self-disclosure  & 7
& \cite{andrews2012system}\cmt{[38]}\cite{lee2020hear}\cmt{[23]}\cite{lubold2016effects}\cmt{[86]}\cite{moilanen2022measuring}\cmt{[82]}\cite{roy2021users}\cmt{[71]}\cite{volkel2021manipulating}\cmt{[68]}\cite{volkel2022user}\cmt{[75]}
\\ \cline{2-5}

& Initiative & proactive dialogue, conversation \newline repair & 4
& \cite{ashktorab2019resilient}\cmt{[88]}\cite{cuadra2021my}\cmt{[67]}\cite{kraus2020effects}\cmt{[64]}\cite{xiao2021let}\cmt{[73]}
\\ \cline{2-5}

& Response Delay & response delay, typing indicator & 4
& \cite{gnewuch2018faster}\cmt{[19]}\cite{gnewuch2018chatbot}\cmt{[21]}\cite{gnewuch2022opposing}\cmt{[20]}\cite{seeger2021chatbots}\cmt{[35]}
\\ \Xhline{1.2pt}

\multirow{2}{*}{Content Affectiveness} & Affective Language & emotional expressions, sentiment-adaptive responses & 11
& \cite{daher2020empathic}\cmt{[58]}\cite{diederich2019emulating}\cmt{[25]}\cite{healey2013relating}\cmt{[39]}\cite{hu2022polite}\cmt{[76]}\cite{lee2019s}\cmt{[55]}\cite{lubis2019positive}\cmt{[43]}\cite{moilanen2022measuring}\cmt{[82]}\cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2022user}\cmt{[75]}\cite{yang2017perceived}\cmt{[44]}\cite{zhu2022effects}\cmt{[26]}
\\ \cline{2-5}

& Humour & humorous content, jokes & 6
& \cite{ceha2021can}\cmt{[57]}\cite{go2021conversational}\cmt{[80]}\cite{khooshabeh2011does}\cmt{[37]}\cite{miyamoto2017improving}\cmt{[46]}\cite{niewiadomski2013laugh}\cmt{[85]}\cite{volkel2021manipulating}\cmt{[68]}
\\ \Xhline{1.2pt}

\multirow{3}{*}{Content Style} & Formality & formal vs. casual, honorific \newline expressions & 9
& \cite{cox2022does}\cmt{[27]}\cite{elsholz2019exploring}\cmt{[61]}\cite{habler2019effects}\cmt{[63]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2019comparing}\cmt{[89]}\cite{ma2022ask}\cmt{[29]}\cite{moilanen2022measuring}\cmt{[82]}\cite{ouchi2019should}\cmt{[59]}\cite{volkel2022user}\cmt{[75]}
\\ \cline{2-5}

& Alignment & content matching, lexical \newline alignment, agreeableness & 7
& \cite{healey2013relating}\cmt{[39]}\cite{hoegen2019end}\cmt{[31]}\cite{huiyang2022improving}\cmt{[17]}\cite{linnemann2018can}\cmt{[15]}\cite{spillner2021talk}\cmt{[18]}\cite{volkel2021examining}\cmt{[69]}\cite{volkel2021manipulating}\cmt{[68]}
\\ \cline{2-5}

& Elaborateness & elaborate, concise, sentence \newline structure & 6
& \cite{haas2022keep}\cmt{[78]}\cite{miehle2018exploring}\cmt{[51]}\cite{moilanen2022measuring}\cmt{[82]}\cite{roy2021users}\cmt{[71]}\cite{volkel2021manipulating}\cmt{[68]}\cite{volkel2022user}\cmt{[75]}
\\ \Xhline{1.2pt}

\multirow{3}{*}{Speech Format} & Prosody & pitch, intonation, speech rate, \newline spoken accent & 12
& \cite{chan2021kinvoices}\cmt{[74]}\cite{choi2020nobody}\cmt{[54]}\cite{dubiel2020persuasive}\cmt{[60]}\cite{feijoo2021effects}\cmt{[70]}\cite{habler2019effects}\cmt{[63]}\cite{hu2021enhancing}\cmt{[56]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2020can}\cmt{[24]}\cite{lubold2016effects}\cmt{[86]}\cite{misu2011toward}\cmt{[83]}\cite{tolmeijer2021female}\cmt{[62]}\cite{zhu2022effects}\cmt{[26]}
\\ \cline{2-5}

& Disfluency & fillers, interjections, repetitions, \newline typos & 6
& \cite{ceha2022expressive}\cmt{[77]}\cite{hu2021enhancing}\cmt{[56]}\cite{jeong2019exploring}\cmt{[10]}\cite{wester2015artificial}\cmt{[14]}\cite{westerman2019believe}\cmt{[9]}\cite{yang2021effect}\cmt{[72]}
\\ \cline{2-5}

& Text Formatting & capitalization, emoticons & 6
& \cite{fadhil2018effect}\cmt{[52]}\cite{kim2019comparing}\cmt{[89]}\cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2022user}\cmt{[75]}\cite{westerman2019believe}\cmt{[9]}\cite{wilhelm2022keep}\cmt{[28]}
\\ \Xhline{1.2pt}
\end{tabular}%
}
\caption{Conversation architecture elements}
\label{tab:cues}
\end{table*}

\subsection{Conversation Architecture Elements}

As shown in Table \ref{tab:cues}, there are four categories defined for conversation architecture across 12 different elements. The details of each category and element are discussed below.

The category of \textbf{dialog strategy} refers to the approach used by a conversational agent to engage in a dialogue with a user, which includes the use of social dialogs, agent-initiated content, and adding delays to responses. Specifically, the element of \textit{social dialogue} captures non-task related conversations with the user to build social connection, such as self-disclosure \cite{lee2020hear}\cmt{[23]} and small talk like chitchats \cite{lubold2016effects}\cmt{[86]}\cite{volkel2021manipulating}\cmt{[68]}. The element of \textit{initiative} captures utterances that are initiated by the agent without direct prompts from the user. For example, the agent is taking the initiative to proactively repair the conversation with a user \cite{ashktorab2019resilient}\cmt{[88]}\cite{cuadra2021my}\cmt{[67]}, or actively elicit feedback from users \cite{xiao2021let}\cmt{[73]}. Lastly, \textit{response delay} refers to the tactic of deliberatively delaying for a certain period of time before an agent responds to users \cite{gnewuch2018faster}\cmt{[19]}\cite{gnewuch2022opposing}\cmt{[20]}. It is mainly used in text-based CAs alongside visual displays of typing indicators \cite{gnewuch2018chatbot}\cmt{[21]}.

\textbf{Content affectiveness} refers to the conversational agent's use of language to convey emotions or to elicit emotions from users. The architecture element of \textit{affective language} captures the injection of emotional words or phrases into the agent's utterance, such as affective expressions \cite{seeger2021chatbots}\cmt{[35]}\cite{yang2017perceived}\cmt{[44]}\cite{zhu2022effects}\cmt{[26]}, sentiment-adaptive responses \cite{diederich2019emulating}\cmt{[25]}, and encouraging words \cite{healey2013relating}\cmt{[39]}. The other element in this category, \textit{humour}, captures an agent's attempt to include jokes in its dialog. Several studies in our reviewed corpus have explored the effect of humour on various perceptions of agents (e.g. \cite{ceha2021can}\cmt{[57]}\cite{khooshabeh2011does}\cmt{[37]}).

The category of \textbf{content style} refers to the variations of language used in a message aside from the content meaning of the message (i.e. how something is said). The element of \textit{formality} describes the linguistic style used by the conversational agent, whether it is formal vs. casual, such as using honorific expressions to address users \cite{ouchi2019should}\cmt{[59]}. \textit{Alignment} captures the degree that the agent aligns its utterances to the users, such as lexical alignment on the content and structural of the sentences \cite{huiyang2022improving}\cmt{[17]}\cite{linnemann2018can}\cmt{[15]}, as well as referring and agreeing with users' utterances \cite{volkel2021examining}\cmt{[69]}. Lastly, the element of \textit{elaborateness} captures the sentence complexity and length of agents' utterances. For example, Roy et al. explored the differences in perception for variations in elaborateness such as "Cloudly, possibility of snow, high: 4, low: -10" vs "Today will be cloudy, with a high of 4 and a low of -10. Snow is predicted" \cite{roy2021users}\cmt{[71]}.

Lastly, the category of \textbf{speech format} captures the non-verbal component of a conversational agent's utterances for both text and voice modalities. \textit{Disfluency} captures 
the use of non-lexical utterances like filler words ("um, uh") \cite{hu2021enhancing}\cmt{[56]}\cite{jeong2019exploring}\cmt{[10]}, or repetition of words within a sentence \cite{yang2021effect}\cmt{[72]}. It also includes the format of using typos \cite{westerman2019believe}\cmt{[9]} for text-based agents. For voice-based agents specifically, the element of \textit{prosody} encompasses vocal qualities like pitch \cite{habler2019effects}\cmt{[63]}\cite{jestin2022effects}\cmt{[81]}, speech rate \cite{choi2020nobody}\cmt{[54]}, and spoken accent \cite{feijoo2021effects}\cmt{[70]}. For text-based CAs, the \textit{text formatting} element includes different formats agents uses to present information to users, such as using capitalization \cite{westerman2019believe}\cmt{[9]} or emoticons \cite{kim2019comparing}\cmt{[89]}\cite{wilhelm2022keep}\cmt{[28]}. 

Overall there are similar number of conversation architecture elements explored across the four categories of dialog strategy, content affectiveness, content style, and speech format. As for explorations related to different modalities of agents, there is a noticeable difference in the category of speech format, where architecture elements related to voice-based agents (n=15) are explored more than text-based agents (n=7). Looking across the 12 different elements, there is good coverage of studies on the impact of affective language and prosody cues on the perceptions of agents. However, there are less studies exploring the effect of agent initiated content and response delay on the perception of agents. Specifically for the element of initiative under dialog strategy category, there is literature on conversation repairs \cite{komatani2010online}\cite{reinkemeier2022repair} and agent proactively sharing content with users \cite{dubiel2019inquisitive}\cite{zargham2022understanding}, but many of them did not not include assessments of perceptions of the CA. This may be due to the fact that the usage of agent-initiated content is relatively new, as CA interactions have historically been driven by users. As such, current research is focused on the functional aspects of agents initiating contents instead of exploring the perceptions of agents. As for response delay, there are indications that this element is under-explored in literature. Only 4 studies in our reviewed corpus used an agent with response delay, and the majority of these publications were written by the same authors.


\subsection{Relationship Between Perceptions of Agents and Conversation Architecture}

There are 183 identified relationships between perceptions of agents and conversation architecture out of the 265 explored connections that are included in our synthesized framework (Figure \ref{fig:heatmap-impact}). To compare the number of identified relationships vs. the explored connections in literature, Figure \ref{fig:heatmap-coverage} shows a side-by-side comparison between the two. The detailed analysis on the differences between explored and identified relationships are discussed in the subsections below.

While the number of papers studying CAs with voice (n=27) vs. text (n=30) modalities is not significantly different, there are some interesting patterns we found with regards to the modalities of the identified relationships between perceptions of agents and conversation architecture. Overall, we confirmed the pattern found earlier that there are more conversation architecture elements explored related to voice vs. text in the speech format category. Because there are smaller number of text-based CAs using speech format elements, we also observed significantly less number of relationships between text-based CA across all perceptions of agents. other interesting findings related to modality are discussed later in this paper.

\begin{figure*}[]
  \centering
  \includegraphics[width=\textwidth]{fig-heatmap-coverage.png}
  \caption{Heatmap of literature for perception of conversational agents for each type of conversational architecture element}
  \label{fig:heatmap-coverage}
\end{figure*}

\subsubsection{Perception of Interaction with Agent}

The effects of conversation architecture elements on the perception of interaction with agent is the most explored connections in the corpus (n=97). Out of these explored connections, the majority of them (n=66) discovered a relationship between aspects of perception related to the perception of interaction with agent related to the studied architecture element. Looking at the difference between modalities, we noticed more voice-based agents (n=25) resulted in null relationships compared to text-based agents (n=6). The conversation architecture element of \textit{alignment} contributed the most to the null results for voice-based agents, with 9 out of 11 explored connections did not find any relationships related the perception of interaction with agents.

Across the aspects for the perception of interaction, both \textit{usability} and \textit{engagement} were assessed frequently in the reviewed literature, with conversation architecture having effects on these perception aspects across all architecture element categories. The aspect of \textit{satisfaction} was used in some studies to evaluate perception but it is not used as often as engagement or usability. Several papers that assessed user satisfactions were conversation agents within the transaction context, especially within the customer service domain (e.g. \cite{diederich2019emulating}\cmt{[25]}\cite{elsholz2019exploring}\cmt{[61]}\cite{gnewuch2018faster}\cmt{[19]}).

The category of conversation architecture elements with the most identified relationships to perceptions of interaction is \textit{content style}. Specifically for the element of \textit{elaborateness}, users found the use of full sentences more useful than keyword only \cite{haas2022keep}\cmt{[78]}\cite{roy2021users}\cmt{[71]}. Otherwise, the effect of an agent's elaborateness on user's perception of interaction depends on the user's preference \cite{miehle2018exploring}\cmt{[51]}, as well as the topic of discussion \cite{haas2022keep}\cmt{[78]}. As for \textit{formality}, various studies reported significant differences in perceptions of interaction between using casual vs. formal styles. Some users experienced higher engagement with agent interacting with the casual style of the conversation \cite{cox2022does}\cmt{[27]}, while in another study users reported the formal language style as less engaging as it is boring \cite{kim2019comparing}\cmt{[89]}.

The speech format of an agent also resulted in a high number of identified relationships with the perception of interaction with CAs, with majority of the explored connections resulted in effects between the perception aspects and architecture elements. The element with the most identified relationships is \textit{prosody}. For example, studies found that a CA's expressiveness in vocal cues increased participants' engagement ratings \cite{zhu2022effects}\cmt{[26]}, and different pitches of voice affect users' perception of engagement and usability \cite{chan2021kinvoices}\cmt{[74]}\cite{habler2019effects}\cmt{[63]}.

Dialog strategy and content affectiveness categories of conversation architecture did not have as many identified relationships with perceptions of interaction. It is worth noting the effect of using the \textit{initiative} element, as CAs that use self-initiated content are perceived as more efficient and higher quality of interaction (e.g. \cite{cuadra2021my}\cmt{[67]}). Also, some studies have discovered conflicting effects between different perception aspects of interaction for CAs using \textit{social dialog}, as users enjoyed the conversation using social talk \cite{lee2020hear}\cmt{[23]}\cite{roy2021users}\cmt{[71]}, but perceived the CA as less efficient \cite{roy2021users}\cmt{[71]}.

\subsubsection{Perception of Agent's Ability}

The effects of conversation architecture elements on the perception of agent's ability is the least explored connection in the corpus (n=39). Out of these explored connections, the majority of them (n=30) found relationships between the studied architecture element and the perceptions of agent's ability. There are no notable differences between the text and voice modalities of CAs for either explored connections or the identified relationships.

Aspects within the perception of agent's ability had similar number of identified relationships across intelligence, competence and credibility. Our review revealed that the perceived ability of a CA is also dependent on other influencing factors in addition to conversation architecture elements. Volkel et al. \cite{kraus2020effects}\cmt{[64]} found that the perception of competence of a proactive CA is dependent on task difficulty \cite{kraus2020effects}\cmt{[64]}. Also, the perception of intelligence for an agent using fillers depended on the context of the conversation, as the filler-speaking agent was perceived as less intelligent in task-oriented conditions, but was seen as slightly more intelligent in social-oriented conditions \cite{jeong2019exploring}\cmt{[10]}.

Out of the explored conversation architecture elements, \textit{prosody} had relationships identified with aspects across the perception category of agent's ability. For example, Chan et al. \cite{chan2021kinvoices}\cmt{[74]} found that agents using kin's voices are rated as more intelligent and credible than generic voices. Also, the style of speech used by an agent affects the perception of appropriateness of tone, which is an aspect of the perceived competence of an agent \cite{misu2011toward}\cmt{[83]}. Different content styles of \textit{formality} also impacts the perceived competence of an agent \cite{cox2022does}\cmt{[27]}\cite{jestin2022effects}\cmt{[81]}. Specifically related to perceived credibility of an agent, being \textit{lexically aligned} with the user resulted improved the rating of trustworthiness of an agent \cite{hoegen2019end}\cmt{[31]}\cite{linnemann2018can}\cmt{[15]}. There were mixed results on the use of emoticons within the \textit{text formatting} element. One study found the chatbot using emoticons as less trustworthy \cite{wilhelm2022keep}\cmt{[28]}, while another study found that users assigned higher scores for confidence to the agent using emojis \cite{fadhil2018effect}\cmt{[52]}. 

There are several conversation architecture elements with little to no explorations to the perception of agent's ability. Specifically, both categories of dialog strategy and content affectiveness are minimally explored in our reviewed corpus, with no explored connections with \textit{response delay} and only one or two connections explored for \textit{social dialog} and \textit{humour}. While the content style category had coverage in some aspects of perceived abilities, it is worth noting that \textit{elaborateness} did not have any explored connections with perceived ability of agents. Further research in these areas is needed to fill these gaps.

%% CW - second pass up to here Feb 15

\subsubsection{Perception of Sociability with Agent}

There are 53 explored connections between conversation architecture elements and the perception of social connection with agents, with majority of them (n=40) resulted in relationships with effects. Interestingly, studies explored more perceptions of social connection with agent related to voice-based CAs (n=34) compared to text-based CAs (n=19), potentially due to the assumption that voice-based agents is more suitable to cultivate human-agent relationships. There are some mixed results for voice-based CAs, as 10 out of the 34 connections did not find any significant results. Half of the neutral results come from the conversation architecture element of \textbf{prosodic cues}. For example, the pitch of agents' voices did not impact the perceived rapport \cite{lubold2016effects}\cmt{[86]} between agent and users or the appropriateness of tone \cite{jestin2022effects}\cmt{[81]}. However, there are also findings that the use of vocal cues made the agent sound more empathetic \cite{tolmeijer2021female}\cmt{[62]}, as well as increased perceived emotional connection \cite{chan2021kinvoices}\cmt{[74]}\cite{kim2020can}\cmt{[24]}. This shows that there are nuanced factors within prosodic cues that impact the perception of social connections that we have not captured in our relationships.

%For humour: Clark et al. \cite{clark2019makes} found that humour is an important conversational characteristic for human-human interactions, but viewed as a novelty feature for human-agent conversations.

Across the themes in this perception category, \textbf{social presence} (n=17) and \textbf{conversation tone} (n=18) have similar number of relationships between architecture elements and perceptions, but \textbf{intimacy} (n=5) has less number of impactful relationships. One reason for this is half of the explored connections did not have any effect on the perception of social connection, such as the use of capitalization \cite{westerman2019believe}\cmt{[9]}, lexical alignment \cite{linnemann2018can}\cmt{[15]}, or social dialogue \cite{lubold2016effects}\cmt{[86]}. For \textbf{social presence}, conversation architecture elements from \textbf{non-linguistic format} category, prosodic cue and text variation, had a number of impactful relationships in the reviewed studies. For example, participants conversing with the agents using kin's voices experienced significantly higher perceived co-presence where there is a closer psychological connection with the agent \cite{chan2021kinvoices}\cmt{[74]}. Also, text-based agents including a delay before responding to users were rated higher in social presence ratings compared to the agent that did not use any response delays \cite{gnewuch2018faster}\cmt{[19]}\cite{gnewuch2022opposing}\cmt{[20]}. Lastly, the use of \textbf{prosodic cues} can impact the perceived \textbf{conversation tone} of the agent as emotionally expressive \cite{zhu2022effects}\cmt{[26]} or persuasive \cite{chan2021kinvoices}\cmt{[74]}, as well as the appropriateness of the tone used by the agent \cite{jestin2022effects}\cmt{[81]}\cite{misu2011toward}\cmt{[83]}.

Looking at the different categories of conversation architecture cues, the heatmap (Figure \ref{fig:heatmap-impact} shows that there are not many relationships in \textbf{linguistic style} that are related to the perceived social connection with CAs. There are not many explored connections in our reviewed corpus between the two, which could be an indication of the assumption that linguistic style does not impact the perception of social connections.
While we discussed the impact of non-linguistic elements of prosodic cues and text variations earlier, the conversation architecture elements in the linguistic content category also had effects on the perception of social connections. Specifically, CAs using of \textbf{affective language} were perceived to be more empathetic \cite{daher2020empathic}\cmt{[58]}\cite{diederich2019emulating}\cmt{[25]}\cite{yang2017perceived}\cmt{[44]} and emotionally expressive \cite{zhu2022effects}\cmt{[26]}, and emotional connection with the agent \cite{lee2019s}\cmt{[55]}\cite{lubis2019positive}\cmt{[43]}.

%add text variation in the discussion

\subsubsection{Perception of Agent's Humanness}

Agent's humanness is the second most explored perception within our reviewed corpus (n=76), with majority of the connections finding impacted relationship between the studied conversation architecture elements and the perception of agent's humanness (n=56). While the connections were explored more for voice-based agent (n=49) as compared to text-based agents (n=27), the actual impacted relationships between the modalities were similar (voice=32, text=24). This is due to larger number of neutral relationships within voice modality, such as the use of affective language for a speech agent did not impact its perceived likeability \cite{hu2022polite}\cmt{[76]}.

Across the themes in this perception category, both \textbf{human-likeness} and \textbf{personality traits} have relationships with almost all conversation architecture elements. Based on the reviewed corpus, it seems like all the conversation architecture elements extracted from literature have some impact on the perception of agent's humanness. However, the impacts can be both positive or negative. In the case of Chan et al's study \cite{chan2021kinvoices}\cmt{[74]}, participated rated the agent using kin voices as significantly more likeable compared to the generic voices, but it was perceived as eerie. As for the perceptions within this category, there are more relationships for perceived personality traits (n=33) vs. human-likeness (n=18). This is because many studies only have one measure for human-likeness (e.g. artificial or human-like), but have multiple aspects of personality to be explored. For example, participant rated the agent using affective language as more polite, as well as reflected that the agent seemed friendly \cite{hu2022polite}\cmt{[76]}. 

For the conversation architecture elements, formality in the linguistic style category and prosodic cue in the non-linguistic format category had more effects on the perception of agent's humanness in the reviewed corpus. For \textbf{formality}, agents using casual style is perceived as more human-like with a warm, kind and entertaining personality \cite{cox2022does}\cmt{[27]}\cite{jestin2022effects}\cmt{[81]}\cite{kim2019comparing}\cmt{[89]}. The use of \textbf{prosodic cues} varying pitch, intonation and speech rate of a conversation agent generally had impacts on the perceived humanness instead of personality traits \cite{choi2020nobody}\cmt{[54]}\cite{jestin2022effects}\cmt{[81]}\cite{misu2011toward}\cmt{[83]}. For the architecture elements of \textbf{disfluency}, the type of impact on the perception of humanness depended on the context of the conversation. Studies have found that participants perceived the filler-condition agent as more likeable in the social-oriented situation, but did not find the same effect in task-oriented situations \cite{jeong2019exploring}\cmt{[10]}\cite{wester2015artificial}\cmt{[14]}.





%-------------
\section{Discussions}

\subsection{Research Challenges and Opportunities}

%Three major needs emerged from the trends identified by our review: 1) 2) 3).

\subsubsection{Inconsistencies in Perception Measures}

A major roadblock in synthesizing the findings from existing academic research is the diversity and inconsistency of measurements towards the anthropomorphized perception of agents. It is difficult to assess whether perception measures should be compared with each other. Also, some measures combined anthropomorphized perceptions into a composite score, which makes it impossible to separate the perceptions into more granular details.

Based on the literature reviewed in this paper, we noticed that similar perception concepts were \textbf{measured in different ways} through different surveys. For example, there are several approaches to measure the perceived \textit{human-likeness} of an agent. A commonly used survey is adapted from the Godspeed questionnaire \cite{bartneck2009measurement}, which measures human-likeness based on user's impression of the agent as fake / natural, machinelike / humanlike, unconscious / conscious, and artificial / lifelike (used by \cite{hoegen2019end}\cmt{[31]}, \cite{jeong2019exploring}\cmt{[10]} and \cite{ouchi2019should}\cmt{[59]}). Another way to measure human-likeness is adapted from Holtgraves et al.'s \cite{holtgraves2007perceiving} questionnaire, which asks users to assess the agent's perceived human-likeness, skillfulness, thoughtfulness, politeness, responsiveness and engagement (used by \cite{diederich2019emulating}\cmt{[25]} and  \cite{gnewuch2018faster}\cmt{[19]}). One study \cite{westerman2019believe}\cmt{[9]} used the Ascend of Man pictorial scale \cite{kteily2015ascent} as the measure of perceived human-likeness. It is unclear whether these different measures of perceived human-likeness are similar enough to be compared with each other.

 In addition to different methods used to measure for the same perception, our detailed analysis revealed that the measures using the same label may have \textbf{different meanings}. In Diedrech et al.'s study \cite{diederich2019emulating}\cmt{[25]}, \textit{empathy} measure is adapted from \cite{yan2013role} assessing whether the CA gives users individual or personal attention. In Daher et al.'s study \cite{daher2020empathic}\cmt{[58]}, they also measure the perception of empathy, but it is using the RoPE Scale \cite{charrier2019rope} with questions like "the robot cares about my feelings" or "the robot comforts me when I am upset." These two different measures of empathy seem to have different underlying meanings, one assessing the personalization aspect of CAs, while the other is assessing the emotional aspect of CAs. Another example is the measurement of \textit{trustworthiness}, with some constructs measuring the level of sensitive information user's are willing to share \cite{dinev2006privacy}, and some measuring the honesty and truthfulness of an agent \cite{lee2017enhancing}. 

Lastly, there are \textbf{composite measures} of anthropomorphized perception across different categories, making it difficult to break down perceptions into granular details for analysis. One such example is Ma et al's study \cite{ma2022ask}\cmt{[29]} on different approaches for CAs to reply to users' uncertain queries. UX score is used to measure the perception of an agent, which asks whether the user thinks the CA's response is pleasing / trustworthy / natural / acceptable / shorten the distance between CA and user. While the study has found significant impact of the use of formal language on UX score, it is not possible to breakdown the measure into perceptions of interaction (pleasing, acceptable), social connection (shorten the distance between CA and user), and humanness (natural, trustworthy). Similar for Hoegen et al.'s study \cite{hoegen2019end}\cmt{[31]} on the impact of conversational style matching, it is not possible to separate the overall interaction score into different perceptions as the composite measure contains questions measuring different categories of perceptions like interaction (engaging) and humanness (trust, likable).

In recent years there has been some effort towards unifying the evaluation of conversational agents, such as the work by Finch et al. \cite{finch2020towards} presenting a comprehensive analysis of current evaluation protocols. More work is needed to categorize and consolidate perception measures to make them consistent and comparable across various studies. 


\subsubsection{Nuances in Influencing Factors}

While the discussion in the Framework section above focuses on the overall effect of conversational architecture elements on anthropomorphized perceptions,  there are other nuanced influencing factors that impact user perceptions of agents. 

Depending on the \textbf{type of conversation} user is having with agents, it may lead to differences in perceptions for similar conversational architecture elements. Cox et al. \cite{cox2022does}\cmt{[27]} found that the perceived competence and appropriateness of tone of different language formality styles depend on the sensitivity of information discussed in the conversation. In this particular study, a formal language style is preferred in medical history discussions as it is matching to the expectation of users, but there is no difference in perception between formal and casual styles when discussing income level and credit scores. In Jeong et al's study \cite{jeong2019exploring}\cmt{[10]}, users found the agent using fillers less intelligent and likable in a task-oriented conversation, but found the same agent using fillers as slight more intelligent and likable in a social-oriented conversation. Another factor that could impact perceptions is the \textbf{anonymity} of conversation. Based on user feedback, Lee et al. \cite{lee2020hear}\cmt{[23]} found that the anonymity of a conversational agent is a driving factor encouraging people to self disclose without having to worried about judgements from the CA. The perception of the agent may be different if the user's identity is not anonymous.

Other than the type of conversation, \textbf{user's characteristics} can also be influencing factors on their perception of agents. For example, the effect of matching user's conversational style on perception of agents depend on user's own conversational style, as participants with high consideration conversational style rated the lexically aligned agent as more trustworthy \cite{hoegen2019end}\cmt{[31]}. In the study by Cox et al. \cite{cox2022does}\cmt{[27]}, participants with lower levels of privacy concerns as well as those who believe in robotic intelligence found the chatbot more enjoyable, warm, competent and appropriate. Similarly, participants with positive attitudes towards computers were significantly more likely to indicate that the usage of fillers by agents was a positive aspect of the conversation, compared to participants with neutral attitudes towards computers \cite{pfeifer2009should}\cmt{[12]}. Lastly, user's prior experience with conversational agents could impact perception of agents. Experienced users perceived the agent with a response delay as lower in social presence compared to the one without delay, as it is seen as inefficient to wait for the CA to respond. However, novice users perceived higher social presence conversing with the CAs using response delays as it is more similar to conversations with human partners \cite{gnewuch2018faster}\cmt{[19]}.


%Designing for personalities, not individual elements

%* The size of the effect for language we observed is clearly higher than the size of the effect for voice. \cite{habler2019effects}\cmt{[63]}

%Combined effects
%* integrated mental model \cite{knijnenburg2016inferring}\cmt{[34]}
%* Anthropomorphized chatbot (text) using affective language (emotional expressions), self-referencing, emoticons, response delays. Resulted in higher perceived anthropomorphism, which in result led to lower negative word of mouth and loss of trust. anthropomorphic design is beneficial not only to initial trust but also to the ongoing trust relationship \cite{seeger2021chatbots}\cmt{[35]}

%For discussions on mental well beings, agent using emojis is rated higher for attitude (emotional connection) . However, for agent with discussing physical well being, agent using emojis is rated as lower for attitude. 
%Attitude has emotional connection, coherent - coherent is an ability perception, vs. emotional connection is a social connection perception. \cite{fadhil2018effect}\cmt{[52]}

%* Format: Response delay - Novice users perceived the agent as more socially present, but experienced users had a negative effect \cite{gnewuch2022opposing}\cmt{[20]}
%* Content: Humour - no overall significant difference between conventional method vs. agent using humour for enjoyment. Specifically, men enjoyed the agent's jokes more than women.  \cite{miyamoto2017improving}\cmt{[46]}.
%* Format: Proactivity - significant interaction between proactive dialogue strategies and task difficulty for perceived competence and perceived reliability. For easier tasks, system help is not really required. \cite{kraus2020effects}\cmt{[64]}
%* Preference for the level of social talk depended on the task, even within the same transactional context, as users preferred high level for playing a song, but low level for writing a text. \cite{volkel2021manipulating}\cmt{[68]}
%* Correlation between user's personality of agreeableness vs. preference for agreeable level of chatbot \cite{volkel2021examining}\cmt{[69]}
%* For expertise, multilingual students rated higher the non-native English-speaking virtual human. \cite{feijoo2021effects}\cmt{[70]}
%* Participants felt irritated when humorous statements were made when they talked about experiencing sadness \cite{go2021conversational}\cmt{[80]}

%\subsubsection{Study Design}

%\textbf{Interview vs experiment}
%* Humour - what's said vs. study results

%\textbf{Observer study vs. interaction study}
%* In observer study, participants attributed higher integrity (trustworthiness), response accuracy and likeability to the agent with lexical alignment, but this effect was not observed in the interaction study. Also, interaction study had lower cognitive demand but no effect in the observer study. \cite{linnemann2018can}\cmt{[15]}
%* \cite{zhu2022effects}\cmt{[26]}
%* \cite{cox2022does}\cmt{[27]}

%* that a sense of intimate connection to the CA is more important than efficient task handling in some contexts \54
%* VA self-repair can backfire if time or accuracy is of the essence. (repair and accuracy) \cite{cuadra2021my}\cmt{[67]}

%Sometimes a study is covering multiple conversational element cues, hard to break it out. For example, extroverted personality used in \cite{volkel2022user}\cmt{[75]} has emoticons, affective language, talkative, and self-disclosure. Need to break it down.

%Also, breaking down "personalities" to its core components.

%There are a few studies that designed conversational agents composed with multiple conversation architecture elements. This is especially evident in studies comparing different personalities of CAs, such as extroverted vs. introverted. In Volkel et al's study, the personality of extraversion is a combination of linguistic content like social ta

%\cite{moilanen2022measuring}\cmt{[82]}\cite{seeger2021chatbots}\cmt{[35]}\cite{volkel2021manipulating}\cmt{[68]}\cite{volkel2022user}\cmt{[75]}.

\subsubsection{Consider Relationships Within Perceptions}

There are empirical evidence that different perceptions of agent have effects on each other. Moussawi et al \cite{moussawi2021perceptions}\cmt{[36]} conducted a study to understand the correlations between different perceptions impacting user's intention to adopt a conversational agent. Specifically, they found a correlation within the category of perceived ability, where perceived intelligence is positively correlated to initial trust of the agent. Also, the study found that users with higher perceived intelligence of an agent are more likely to attribute higher ratings for the perception category of interaction on the perceived ease of use and enjoyment, as well as higher ratings for perceived anthropomorphism. Perceived anthropomorphism have a positive impact on perceived enjoyment, which lead to higher intention to adopt the CA. This study outlines that the perception themes we identified in this paper are not independent of each other.

The correlations between perception measures are covered in a few of the papers in our corpus. In the study of using response delays, the perception of social presence had a significant effect on the intention to use \cite{gnewuch2022opposing}\cmt{[20]}. In another study, the CA's perceived personality trait of agreeableness has an influence on the perception of trust \cite{andrews2012system}\cmt{[38]}. Seeger et al's study had similar findings, where higher perceived anthropomorphism lead to lower loss of trust \cite{seeger2021chatbots}\cmt{[35]}. There are also effects within the same perception category, such as a speech agent that is rated higher in perceived human-likeness was associated with higher likability ratings \cite{zhu2022effects}\cmt{[26]}. Also, within the perception category of social connection, one study found that social distance is positively related to the perceived social attraction \cite{westerman2019believe}\cmt{[9]}. 

These correlations between perceptions demonstrate that designing for specific anthropomorphized perceptions of conversational agents is more nuanced than the sum of the impacts from individual perceptions. Perceptions have influences on each other, either within the same category or across different categories. However, there is not enough studied connections in existing literature to make a meaningful systematic analysis of the relationship within perceptions. More research is needed in this area to study these relationships, to understand whether there are systematic trends in the influences of perceptions, and whether there is a sequence of perceptions to achieve the desired overall anthropomorphized perception of agents.

\subsection{Ethical Considerations}

%include different age considerations - cite Jaisie's paper

While the use of conversation architecture elements can be used to design anthropomorphized perceptions, it is important to address the potential ethical implications that could negative impact users. There are three items discussed in this section: societal stereotypes, influencing user's actions and privacy concerns.

For prosodic cues, there are various studies in our corpus exploring the effect of different pitches on different perceptions of agents. Even in studies not explicitly studying the effect of gendered voices in an agent, possible stereotypes may still exist in the study. Studies exploring the impact of gendered voices found that lower pitches usually associated with men are considered to be more desirable, authoritative but less friendly \cite{tolmeijer2021female}\cmt{[62]}\cite{jestin2022effects}\cmt{[81]}. For Dubiel et al's study \cite{dubiel2020persuasive}\cmt{[60]}, the prosody setting with the lower mean pitch was selected as the more persuasive voice through a user study. These results may be due to the unconscious bias to select a male sounding voice as more persuasive over female sounding voices that are usually using higher pitches. While some guidelines recommend designing agents to be androgynous to avoid gender stereotypes \cite{ruane2019conversational}, there are limitations in creating gender-ambiguous voices. Currently there is no defined aspects on what is perceived as a gender-neutral voice  \cite{jestin2022effects}\cmt{[81]}, and there is a lack of voice generators available to generate voices that are seen as androgynous \cite{tolmeijer2021female}\cmt{[62]}.

Conversation architecture elements can be used to design perceptions of agents to make the CA more persuasive. This opens up the ethical issue of influencing user's attitudes and behaviours through these persuasion techniques. In a study by Chan et al \cite{chan2021kinvoices}\cmt{[74]}, they found that CAs using kin's voices are perceived as more credible and likeable, with a higher perceived social presence with the agent. These perceptions contributes to the agent being more engaging and persuasive, therefore people are more likely to comply with its requests. Andrew et al \cite{andrews2012system}\cmt{[38]} found that tailoring the personality of the CA to users will positively impact an agent's persuasiveness. These persuasion techniques can be beneficial to help users achieve their goals, but can also be used for harmful actions, such as when trying to get someone to believe false information for their own gain.

Another key area of concern is privacy. Given the natural language format of conversational agents, users may be disclosing more sensitive and personal information than needed for the interaction. In relationship to conversation architecture, some elements like self-disclosure and using persuasive voices resulting in higher trust, leading participants to disclose sensitive information with the agent \cite{lee2020hear}\cmt{[23]}\cite{dubiel2020persuasive}\cmt{[60]}. This can expose users to attacks, such as CAs using voice impersonation to ask for personal information for malicious intents \cite{chan2021kinvoices}\cmt{[74]}. Designing for anthropomorphized perceptions of agents requires careful consideration of privacy issues including the sensitivity of the data, who has access to it, and how to protect against nefarious users.

\subsection{Limitations and Future Work}

Our systematic literature review was limited to papers published in the ACM Digital Library between 2010 and 2022. We may have missed literature published outside this time period, as well as in other libraries. Also, most of the studies in our corpus are based on lab experiments with short interactions. The generalizability of these findings need to be verified through longer term engagements with conversational agents deployed in real world situations. Lastly, research without empirical studies on the perception of agents are excluded based on our selection criteria. We may have missed some influential findings in these papers. To better understand the relationships between conversation architecture elements and the perceptions of agents, we plan to conduct future reviews in literature and user studies to understand their real-world impacts.

<TODO> Add more about perception of abilities, perception of social connections, especially for linguistic cues.


\section{Conclusions}

In this paper, we discussed the results of a systematic review of existing literature published in the ACM Digital Library on the impact of conversation architecture elements on anthropomorphized perceptions of CAs.  Through our synthesis of our corpus of 57 papers, we have created a consistent taxonomy for perceptions of agents, as well as conversation architecture elements. Also, we have mapped the relationships between perceptions and conversation architecture to a generalized framework based on the impacts discussed in our reviewed corpus. Through our analysis, we have found that perception measures are being used inconsistently across studies, as well as other influencing factors on the perception of agents. We recommend future research to consider creating consistent measures that can explore different aspects of perceptions, as well as more explorations into the patterns behind other influencing factors that have impacts on anthropomorphized perceptions. While our research contribute to design conversation architecture to orchestrate specific anthropomorphized perceptions, we urge everyone to incorporate ethical perspectives into their design considerations.

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
TBD
\end{acks}






%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\end{document}
\endinput
%%
%% End of file `paper.tex'.