%% FINDINGS %%

\section{Findings}

In this section, we present our findings on the perception of agents, conversation architecture elements, and their relationship with each other.

\subsection{Perception of Agents}

As shown in \autoref{tbl:perceptions}, we defined four categories for the perceptions of conversational agents covering 11 different aspects of perception. The details of each category and aspect are discussed below.


\textbf{Perception of interaction with agent} assesses the overall interaction quality between users and conversational agents. The three aspects in this perception category  are: usability, engagement and satisfaction. \textit{Usability} captures the utilitarian component of the interaction, whether it was accurate, easy to use, efficient or helpful. Some commonly used methods to evaluate usability include the response accuracy portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, or the NASA Task Load Index (NASA-TLX) \cite{hart1988development}\cmt{nasa} for cognitive workload. Questions such as ``\textit{the system is easy to use}'' or ``\textit{it is easy to understand the agent}'' are also used to evaluate usability. \textit{Engagement} on the other hand captures users' emotional reactions to the CA, including whether they have enjoyed the conversation, or felt annoyed or frustrated with the interaction. Some commonly used methods to evaluate engagement include the annoyance portion of the SASSI questionnaire \cite{hone2000towards}\cmt{sassi}, and the Use Engagement Scale (UES) \cite{o2018practical}\cmt{ues}. Questions such as ``\textit{I enjoyed using the system}'' or ``\textit{I felt frustrated with the agent}'' are also used to evaluate engagement. Lastly, \textit{Satisfaction} captures users' overall satisfaction interacting with the agent. Questions such as ``\textit{the overall assessment of conversing with the CA was satisfactory}'' are used to evaluate this aspect of perception.


\input{tables/tbl-perceptions}

\textbf{Perception of agent's ability} assesses the perceived capabilities of the agent. Unlike system capabilities that affect agent's performance, this perceived ability category captures perceptions of agents with equivalent system capabilities but varied conversation architecture elements. Specifically, \textit{intelligence} captures the agent's perceived expertise and knowledge, and it is commonly administered through the Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} using the set of questions related to perceived intelligence. Also survey questions such as asking users about the agent's intelligence and domain knowledge are used to evaluate perceived intelligence. \textit{Competence} takes intelligence one step further by examining the agent's perceived ability to put its intelligence into practice. Surveys or qualitative feedback are usually used to assess if the agent is capable and competent, and whether users have confidence in the agent's ability to get the job done. Lastly, \textit{credibility} captures agent's perceived truthfulness, benevolence, and user's confidence in CAs. Some commonly used methods to evaluate trust include the Trust Propensity Scale \cite{mayer1999effect} and the Individualized Trust Scale (ITS) \cite{wheeless1977measurement}. Questions such as ``\textit{is the agent honest}'' and ``\textit{can I trust the agent with sensitive information}'' are also used to evaluate trust.

\textbf{Perception of sociability with agent} assesses the emotional connections that users have with conversational agents. This category includes the perception aspects of conversation tone, social presence and intimacy. \textit{Conversation tone} captures the affective impression of the agent's tone, such as empathy and expressiveness. Also, this aspect includes whether the tone used by the agent was perceived as friendly, polite or warm. \textit{Social presence} captures the sense of connectedness and psychological distance users have with an agent. This perception aspect also includes the sense of familiarity or similarity with the agent, and whether users feel the agent behaves like them or has similar attitudes to them. The aspect of \textit{intimacy} extends social presence into the realm of the quality of relationships with an agent. Some commonly used methods to assess intimacy include the set of social attraction questions from the interpersonal attraction questionnaire \cite{mccroskey1975development} and the quality of relationship inventory (QRI) \cite{pierce1997assessing}. These questionnaires include questions like ``\textit{I think the agent could be a friend of mine}'', or ``\textit{I feel we could establish a personal relationship with each other}''.

\textbf{Perception of agent's humanness} assesses the specifics of anthropomorphized perceptions of conversational agents. \textit{Human-likeness} captures whether the agent presented itself as natural and human-like, or artificial and machine-like. The Godspeed questionnaire \cite{bartneck2009measurement}\cmt{godspeed} set of questions related to anthropomorphism and the Ascent of Man scale \cite{kteily2015ascent} are commonly used methods to evaluate human-likeness. Survey questions with semantic scales such as ``\textit{human-like / machine-like}'' and ``\textit{artificial / natural}'' are also used frequently to assess this aspect of perception. \textit{Personality traits} captures the human characteristics that are attributed to the agent. This is commonly collected as qualitative feedback from users, commenting on whether the agent is extroverted or introverted, or its perceived personality such as likeable, funny or witty. Sometimes the Big-5 personality traits questionnaire \cite{gosling2003very} is used to map an agent's disposition on various personality dimensions.

There is good coverage across the four perception categories based on our reviewed corpus. The perception category of interaction with agent is most commonly explored in literature, followed by the perception category of sociability with agent. Some aspects of perception are under explored in literature, such as the perceived intimacy with a CA or the perceived competence of an agent. This may be due to the controlled lab settings for experiments, where participants are given defined scenarios for interaction. This type of environment is not conducive to forming relationships with a conversational partner, as noted by Linnerman et al. in their discussions \cite{linnemann2018can}\cmt{[15]}. The same factor could impact the assessment of an agent's perceived competence, as users may not feel comfortable assessing the expertise of their conversational partner. 

\input{tables/tbl-conversation_architecture}

\subsection{Conversation Architecture Elements}

As shown in \autoref{tbl:conversation_architecture}, we defined four categories for conversation architecture across 11 different elements. The details of each category and element are discussed below.

The category of \textbf{dialog strategy} refers to the approach used by a conversational agent to engage in a dialogue with a user, which includes the use of social dialogs, agent-initiated content, and adding delays to responses. Specifically, the element of \textit{social dialogue} captures the use of non-task related conversations with users to build social connections, such as using self-disclosure \cite{lee2020hear}\cmt{[23]} and small talk \cite{lubold2016effects, volkel2021manipulating}\cmt{[86][68]}. The element of \textit{initiative} captures utterances that are initiated by an agent without direct prompts from users. For example, this element includes CAs designed to proactively initiate conversation repair \cite{ashktorab2019resilient, cuadra2021my}\cmt{[88][67]}, or actively elicit feedback from users \cite{xiao2021let}\cmt{[73]}. Lastly, \textit{response delay} refers to the tactic of deliberately delaying for a certain period of time before an agent responds to users \cite{gnewuch2018faster, gnewuch2022opposing}\cmt{[19][20]}. It is mainly used in text-based CAs alongside visual displays of typing indicators \cite{gnewuch2018chatbot}\cmt{[21]}.

\textbf{Content affectiveness} category refers to the conversational agent's use of language to convey emotions or to elicit emotions from users. The  element of \textit{affective language} captures injections of emotional words or phrases into an agent's utterances, such as the use of affective expressions \cite{seeger2021chatbots, yang2017perceived, zhu2022effects}\cmt{[35][44][26]}, sentiment-adaptive responses \cite{diederich2019emulating}\cmt{[25]}, and encouraging words \cite{healey2013relating}\cmt{[39]}. The other element in this category, \textit{humour}, captures an agent's attempt to include jokes in its dialog. Several studies in our reviewed corpus have explored the effect of humour on various perceptions of agents (e.g. \cite{ceha2021can, khooshabeh2011does}\cmt{[57][37]}).

The category of \textbf{content style} refers to the variations of language used in a message aside from the content meaning of the message (i.e. how something is said). The element of \textit{formality} describes the linguistic style used by a conversational agent, such as using formal language like honorific expressions to address users \cite{ouchi2019should}\cmt{[59]}. \textit{Alignment} captures the degree that an agent matches its utterances to users, such as being lexical aligned with the content and structure of users' sentences \cite{huiyang2022improving, linnemann2018can}\cmt{[17][15]}, as well as agreement with users \cite{volkel2021examining}\cmt{[69]}. Lastly, the element of \textit{elaborateness} captures the sentence complexity and length of agents' utterances. For example, \citet{roy2021users}\cmt{[71]} explored the differences in perceptions for elaborateness variations such as ``\textit{Cloudy, possibility of snow, high: 4, low: -10}'' vs. ``\textit{Today will be cloudy, with a high of 4 and a low of -10. Snow is predicted}''.

Lastly, the category of \textbf{speech format} refers to the non-verbal component of a conversational agent's utterances for both text and voice modalities. \textit{Disfluency} captures 
the use of non-lexical utterances like filler words (``\textit{um, uh}'') \cite{hu2021enhancing, jeong2019exploring}\cmt{[56][10]} or repetition of words within a sentence \cite{yang2021effect}\cmt{[72]}. It also includes the use of typos \cite{westerman2019believe}\cmt{[9]} for text-based agents. For voice-based agents specifically, the element of \textit{prosody} encompasses vocal qualities like pitch \cite{habler2019effects, jestin2022effects}\cmt{[63][81]}, speech rate \cite{choi2020nobody}\cmt{[54]}, and spoken accent \cite{feijoo2021effects}\cmt{[70]}. For text-based CAs, the \textit{text formatting} element includes different formats agents uses to present information to users, such as using capitalization \cite{westerman2019believe}\cmt{[9]} or emoticons \cite{kim2019comparing, wilhelm2022keep}\cmt{[89][28]}. 

Overall there are similar number of conversation architecture elements explored across the four categories of dialog strategy, content affectiveness, content style, and speech format. Looking across the 11 different elements of conversation architecture, there is a good coverage of studies on the effect of affective language and prosody cues on the perceptions of agents. However, there are less studies exploring the effect of agent initiated content and response delay on the perception of agents. Specifically for the element of agent initiated content, we found various research on conversation repairs \cite{komatani2010online, reinkemeier2022repair} and agents proactively sharing content with users \cite{dubiel2019inquisitive, zargham2022understanding}, but many of them did not not include assessments of users' perceptions of CAs. This may be due to the fact that the usage of agent-initiated content is relatively new, as CA interactions have historically been driven by users. As such, current research is focused on the functional aspects of agents initiating contents instead of exploring the perceptions of agents. As for response delay, our research suggests this element is under-explored in literature, as only 4 studies in our reviewed corpus examined agents using response delay, with majority of these publications published by the same authors.

\subsection{Relationship Between Perceptions of Agents and Conversation Architecture}

Our synthesized framework (\autoref{fig:heatmap_identified}) includes 183 identified relationships out of the 265 explored connections between perceptions of agents and conversation architecture elements. The differences between explored connections and identified relationships are shown as a side-by-side comparison in \autoref{fig:heatmap_coverage}, with detailed discussions in the subsections below.
%To compare the number of identified relationships vs. the explored connections in literature, \autoref{fig:heatmap_coverage} shows a side-by-side comparison between the two. The detailed analysis on the differences between explored and identified relationships are discussed in the subsections below.

%While the number of papers studying CAs with voice (n=27) vs. text (n=30) modalities is not significantly different, there are some interesting patterns with regards to the modalities of the identified relationships between perceptions of agents and conversation architecture. Overall, there are more explored conversation architecture elements related to voice-based CAs as compared to text-based CAs in the speech format category. Because there are smaller number of text-based CAs using speech format elements in our corpus, we also observed significantly smaller number of relationships between text-based CA across all perceptions of agents. Other interesting findings related to modality are discussed later in this paper.


\input{figures/fig-heatmap_coverage}

\subsubsection{Perception of Interaction with Agent}

The effects of conversation architecture elements on the perception of interaction with agent is the most explored connections in the corpus (n=97). Out of these explored connections, the majority of them (n=66) discovered relationships between the perceptions of interaction with agent related to the studied architecture element. Looking at the difference between modalities, we noticed more voice-based agents (n=25) resulted in null relationships compared to text-based agents (n=6). The conversation architecture element of \textit{alignment} contributed the most to the null results for voice-based agents, with 9 out of 11 explored connections not finding any relationships related the perception of interaction with agents.

Across the aspects for the perception of interaction, both usability and engagement were assessed frequently in our reviewed corpus, with speech variations having effects on both perception aspects across all conversation architecture element categories. The perception aspect of user satisfaction is commonly used to evaluate conversational agents within the customer service domain answering transactional inquiries (e.g. \cite{diederich2019emulating, elsholz2019exploring, gnewuch2018faster}\cmt{[25][61][19]}).

The category of conversation architecture with the most identified relationships to perceptions of interaction is content style. Specifically for the element of \textit{elaborateness}, users found the use of full sentences more useful than keyword only \cite{haas2022keep, roy2021users}\cmt{[78][71]}. Otherwise, the effect of an agent's elaborateness on user's perception of interaction depends on the user's preference \cite{miehle2018exploring}\cmt{[51]}, as well as the topic of discussion \cite{haas2022keep}\cmt{[78]}. As for \textit{formality}, various studies reported significant differences in the perceptions of interaction between CAs using casual vs. formal styles. However, there are mixed results on the effects on formality, as some users experienced higher engagement interacting with agent using casual style of conversation \cite{cox2022does}\cmt{[27]}, while in another study users found the CA using formal language style as less engaging as it is boring \cite{kim2019comparing}\cmt{[89]}.

There are also a number of papers in our reviewed corpus exploring the effect of speech format elements on the perception of interaction with CAs, with many of them finding significant relationships between them. The element with the most identified relationships is \textit{prosody}. For instance, studies found that a CA's expressiveness in vocal cues increased participants' engagement ratings \cite{zhu2022effects}\cmt{[26]}, and different pitches of voice affect users' perception of engagement and usability \cite{chan2021kinvoices, habler2019effects}\cmt{[74][63]}.

Dialog strategy and content affectiveness categories of conversation architecture did not have as many identified relationships with perceptions of interaction. It is worth noting the effect of using the \textit{initiative} element, as CAs that use self-initiated content are perceived as more efficient and higher quality of interaction \cite{cuadra2021my}\cmt{[67]}. Also, some studies have discovered conflicting effects between different perception aspects of interaction for CAs using \textit{social dialog}. One such example is users enjoying of the conversation with CAs using social talk \cite{lee2020hear, roy2021users}\cmt{[23][71]}, but perceiving the agent as less efficient \cite{roy2021users}\cmt{[71]}.

\subsubsection{Perception of Agent's Ability}

The effects of conversation architecture elements on the perception of agent's ability is the least explored connection in the corpus (n=39). Out of these explored connections, the majority of them (n=30) found relationships between the studied speech element and the perceptions of agent's ability. There are no notable differences between the text and voice modalities of CAs for either explored connections or the identified relationships.

Perception aspects of agent's ability had similar number of identified relationships with speech elements across intelligence, competence and credibility. Our review revealed that the perceived ability of a CA is also dependent on other influencing factors in addition to conversation architecture elements. For instance, \citet{kraus2020effects}\cmt{[64]} found that the perception of competence of a proactive CA is dependent on task difficulty. Also, the perception of intelligence for an agent using fillers depended on the context of the conversation, as the filler-speaking agent was perceived as less intelligent in task-oriented conditions, but was seen as slightly more intelligent in social-oriented conditions \cite{jeong2019exploring}\cmt{[10]}.

The conversation architecture element of \textit{prosody} has relationships identified with each perception aspect of an agent's ability. For example, Chan et al. \cite{chan2021kinvoices}\cmt{[74]} found that agents using kin's voices are rated as more intelligent and credible than generic voices. Also, the style of speech used by an agent affects the perception of appropriateness of tone, which is an aspect of the perceived competence of an agent \cite{misu2011toward}\cmt{[83]}. Different content styles of \textit{formality} used by a CA also impacts its perceived competence \cite{cox2022does, jestin2022effects}\cmt{[27][81]}. Related to the perception aspect of credibility, being \textit{lexically aligned} with the user improved the rating of trustworthiness of an agent \cite{hoegen2019end, linnemann2018can}\cmt{[31][15]}. There are some mixed results on the use of emoticons within the \textit{text formatting} element. One study found that chatbots using emoticons as less trustworthy \cite{wilhelm2022keep}\cmt{[28]}, while another study found that users assigned higher scores of confidence to the agent using emojis \cite{fadhil2018effect}\cmt{[52]}. 

There are several conversation architecture elements with little to no explorations related to the perception of agent's ability. Specifically, both categories of dialog strategy and content affectiveness are minimally explored in our reviewed corpus, with no explored connections with \textit{response delay} and only one or two connections explored for \textit{social dialog} and \textit{humour}. While some speech elements within the content style category have been evaluated for agents' perceived abilities, it is worth noting that the element of \textit{elaborateness} did not have any explored connections with perceived ability of agents. Further research in these areas is needed to close these knowledge gaps. 


\subsubsection{Perception of Sociability with Agent}

The perception of agent's sociability is the second most explored category within our reviewed corpus (n=64), with majority of the connections found relationships between the studied conversation architecture elements and perceptions of agent (n=49). Interestingly, studies explored more perceptions of sociability with agent related to voice-based CAs (n=40) compared to text-based CAs (n=24), potentially due to the assumption that interactions with text-based agents are perceived as less personal and more formal \cite{kocielnik2018designing}. There are some mixed results for voice-based CAs, as 12 out of the 28 explored connections did not find any significant results. Drilling down to the specific elements, we noticed that the use of \textit{alignment} in voice-based agents did not effect the perception of sociability with agent \cite{healey2013relating, linnemann2018can}\cmt{[39][15]}. As there are no papers in our reviewed corpus studying the effect of text-based agents using alignment on the perceptions of sociability, we were not able to compare the effect of alignment between modalities.

Across the aspects in this perception category, perceived conversation tone has the most number of identified relationship (n=27), followed by perceived social presence (n=17). There are only 5 relationships found between speech elements and perceived intimacy. One reason for this is half of the explored connections with speech elements did not have any effect on the perception of sociability with agent, such as the use of capitalization \cite{westerman2019believe}\cmt{[9]}, lexical alignment \cite{linnemann2018can}\cmt{[15]}, and social talk \cite{lubold2016effects}\cmt{[86]}. For the perception aspect of social presence, we noticed a gap exploring elements in the content style category (formality, alignment, elaborateness), as there are no connections explored at this intersection.

Looking at the different categories of conversation architecture elements, the heatmap (\autoref{fig:heatmap_identified}) shows that there are not many relationships in content style category of conversation architecture that are related to the aspects of perceived sociability with CAs. Most of the identified effects are concentrated at the intersection of \textit{formality} and perceived conversation tone. Studies have found that CAs using casual style of conversation are perceived as warm, empathetic and friendly \cite{jestin2022effects, kim2019comparing}\cmt{[81][89]}, while CAs using formal style of conversation are perceived as polite but lacks empathy \cite{cox2022does}\cmt{[27]}. The rest of the speech elements related to the perceptions of sociability are minimally explored in literature, indicating the need for more research in this area.

There are a few specific conversation architecture elements that has more identified relationships with perceptions of sociability with agent. Specifically, CAs using \textit{affective language} are perceived to be more empathetic \cite{daher2020empathic, diederich2019emulating, yang2017perceived}\cmt{[58][25][44]} and emotionally expressive \cite{zhu2022effects}\cmt{[26]}, as well as being more emotional connected with their users \cite{lee2019s, lubis2019positive}\cmt{[55][43]}. Also, different variations of a voice-based CA's \textit{prosody} have effects on the perceived sociability with agent, such as an agent using expressive prosody is assessed as more intimate and more similar with the user \cite{kim2020can}\cmt{[24]}. Lastly, the conversation architecture element of \textit{humour} has identified relationships across aspects of perceived sociability with CAs. Our review found that humor has effects on human-agent relationships, as humorous agents are rated as more friendly, intimate, and similar by users compared to non-humorous agents \cite{go2021conversational, khooshabeh2011does}\cmt{[80][37]}. This is contrary to \citet{clark2019makes}'s findings that while humour is an important conversational characteristic for human-human interactions, it is viewed as a novelty feature for human-agent conversations.


\subsubsection{Perception of Agent's Humanness}

There are 55 explored connections between conversation architecture elements and the perception of sociability with agents, with majority of them (n=38) discovering relationships in literature. There are significantly more explorations for voice-based agents (n=39) as compared to text-based agents (n=16). Previous studies have found that modality may have an effect on the perception of humanness, as voice-based agents are perceived as more human-like as compared to text-based agents \cite{cho2019effects}. Out of the 39 explored connections for voice-based agents, 14 of them did not result in any relationships. This is especially evident in the speech element of \textit{affective language} for voice-based agents, as most of the connections resulted in null relationships. For example, when comparing the ratings of human-likeness or likeability for a speech agent employing expressive words to the one not using any, Zhu et al \cite{zhu2022effects}\cmt{[26]} were unable to detect any statistically significant differences in both of the observation study and interaction study.

Across the aspects in this perception category, both human-likeness and personality traits have relationships with almost all the conversation architecture elements. Specifically for the use of \textit{prosody} in CAs, our review found some opposing effects on the perception of the agent's humanness. In the case of Chan et al's study \cite{chan2021kinvoices}\cmt{[74]}, participants rated the agent using kin voices as significantly more likeable compared to the generic voices, but it was perceived as eerie. This may be a warning indicator to beware of the uncanny valley effect \cite{mori2012uncanny} when designing conversation architecture elements to elicit anthropomorphized perceptions from users.

There are a few notable conversation architecture elements related to the perceived humanness of conversational agents. The element of \textit{prosody} such as varying pitch, intonation and speech rate has more identified relationships with perceived personality traits of an agent as compared to perceived human-likeness, especially on the perception of likeability for an agent \cite{choi2020nobody, jestin2022effects, misu2011toward}\cmt{[54][81][83]}. For the element of \textit{disfluency}, the effect on perceived humanness depended on the context of the conversation. Studies have found that participants perceived the filler-condition agent as more likeable in the social-oriented situation, but did not find the same effect in task-oriented situations \cite{jeong2019exploring, wester2015artificial}\cmt{[10][14]}. The use of \textit{alignment} in an agent has a number of identified relationships with the perception of personality traits of an agent, with some studies finding CAs that are lexically aligned with a user are more likeable \cite{huiyang2022improving, linnemann2018can}\cmt{[17][15]}. 