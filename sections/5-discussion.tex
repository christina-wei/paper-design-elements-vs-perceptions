%% DISCUSSION SECTION %%

\section{Discussion}

\subsection{Research Challenges and Opportunities}

%Three major needs emerged from the trends identified by our review: 1) 2) 3).

\subsubsection{The Need for Consistent Evaluation Protocols for Perceptions of Agents}

We found a diversity of approaches used to assess perceptions of agents in our reviewed corpus. While we made our best efforts to group perceptions used in literature based on similarity with each other, the inconsistent and composite nature of these perception assessments makes it challenging to synthesize them into a framework that contains homogeneous components in each perception aspect that can be compared with each other.

Based on the literature reviewed in this paper, it is unclear whether perception aspects using similar labels are being evaluated \textit{consistently} through different approaches. For example, we found several methods used to assess the perceived human-likeness of an agent. A commonly used survey is adapted from the Godspeed questionnaire \cite{bartneck2009measurement}, which evaluates human-likeness based on users' impression of the agent as fake / natural, machinelike / humanlike, unconscious / conscious, and artificial / lifelike (used by \cite{hoegen2019end}\cmt{[31]}, \cite{jeong2019exploring}\cmt{[10]} and \cite{ouchi2019should}\cmt{[59]}). Another method used to evaluate human-likeness is adapted from Holtgraves et al.'s \cite{holtgraves2007perceiving} questionnaire, which asks users questions related to the agent's perceived human-likeness, skillfulness, thoughtfulness, politeness, responsiveness and engagement (used by \cite{diederich2019emulating}\cmt{[25]} and  \cite{gnewuch2018faster}\cmt{[19]}). One study \cite{westerman2019believe}\cmt{[9]} used the Ascend of Man scale \cite{kteily2015ascent} with pictures showing the evolution from ape to man, asking users to choose a depiction that best represents the agent's perceived human-likeness. It is unclear whether these different methods are capturing assessments of similar perception aspects that can be compared with each other. Another example is the evaluation of the perception of agent's empathy. In Diedrech et al.'s study \cite{diederich2019emulating}\cmt{[25]}, empathy is assessed by asking users whether the CA is giving users individual or personal attention. In another study that also studies the perception of empathy \cite{daher2020empathic}\cmt{[58]}, the RoPE Scale \cite{charrier2019rope} is used with questions like "the robot cares about my feelings" or "the robot comforts me when I am upset." These two different evaluations of empathy seem to have different underlying meanings, one assessing the personalization aspect of CAs, while the other is assessing the emotional aspect of CAs.

In addition the problem of consistency in evaluating perceptions, there is the issue of  \textit{composite measures} being used in the assessment of users' perceptions. These composite measures collapse multiple aspects of perception into one measurement, making it impossible to break down perceptions into more granular aspects for analysis. One such example is Ma et al's study \cite{ma2022ask}\cmt{[29]} on the different approaches for CAs to reply to users' uncertain queries. A single UX score is used to evaluate the users' perceptions, which composes of questions on whether the user thinks the CA's response is pleasing / trustworthy / natural / acceptable / shorten the distance between CA and user. The UX score encompasses multiple aspects across several perception categories. While this study has found significant effect for the use of formal language on the user rated UX score, it is not possible to understand how the details of formality is related to the perception categories of interaction (pleasing, acceptable), sociability (shorten the distance between CA and user), and humanness (natural, trustworthy). The humanness questionnaire from Holtgraves et al \cite{holtgraves2007perceiving} has a similar problem, evaluating across perception categories of interaction (responsiveness, engagement), ability (skillfulness), sociability (politeness), and humanness (human-likeness, thoughtfulness).

There has been some effort recently towards unifying the evaluation of conversational agents, such as the work by Finch et al. \cite{finch2020towards} presenting a comprehensive analysis of current evaluation protocols. More research is needed in this area to standardize the assessment of perceptions to make them consistent, granular, and comparable across literature.

\subsubsection{Investigate the Relationship Across Perception Aspects of Agents}

There is evidence in literature that perception aspects of agents have effects on each other. For instance, Moussawi et al. \cite{moussawi2021perceptions}\cmt{[36]} conducted a study to understand the correlations between different perceptions related to users' intention to adopt a conversational agent. Specifically, they found a correlation within the category of perceived ability, where an agent's perceived intelligence is positively correlated to the perceived initial trust of the agent. This study also found that users with higher perceived intelligence of an agent are more likely to attribute higher ratings for perceived human-likeness, as well as for the usability and engagement aspects in the perception category of interaction. Lastly, the authors found that perceived humanness have a positive impact on perceived enjoyment, which lead to higher intention to adopt the CA. This study outlines that the perception aspects identified in this paper are not independent of each other.

Correlations between perception aspects are discussed in a few of the papers we reviewed. One of the studies showed that the CA's perceived personality trait of agreeableness has an influence on the users' perception of credibility \cite{andrews2012system}\cmt{[38]}. Seeger et al's study found a similar correlation, where higher perceived anthropomorphism led to lower loss of trust \cite{seeger2021chatbots}\cmt{[35]}. There are also correlations between aspects found within the same perception category, such as a speech agent that is rated higher in perceived human-likeness was associated with higher likability ratings \cite{zhu2022effects}\cmt{[26]}. Also, within the perception category of social connection, one study found that social distance is positively related to the perceived social attraction \cite{westerman2019believe}\cmt{[9]}.
 
These correlations demonstrate that some perception aspects have effects on each other, either within the same category or across different categories. While there are limited research into this area, further investigations are needed to understand the relationships between various perception aspects.


\subsubsection{Research Directions for the Effects of Conversation Architecture on Users' Perceptions}

Our synthesized framework (Figure \ref{fig:heatmap-impact}) serves as a foundational understanding on the effect of conversation architecture on the perception of agents. It showcases the density of explored relationships between them, as well as highlighting areas that are under-explored. In order to continue building our knowledge, it is important to investigate further into the effect of contextual factors as well as multiple conversation architecture elements on users' perceptions.

There are a few \textit{under-explored areas} in our synthesized framework. The perception category of agent's ability has the least number of explored connections with conversation architecture compared to other perception categories. Specifically, more studies are needed to understand the effects of social dialog, response delay, humour and elaborateness on users' perceptions of agents' ability. For the perception category of sociability with agent, there is a general lack of explored connections with the conversation architecture category of content style, especially for alignment and elaborateness elements. Lastly, more studies on the effect of dialog strategy for conversation architecture elements of initiative and response delay on the perceptions of agent are needed.

Some studies have discussed how differences in \textit{contextual factors} resulted in variations in the perceptions of agents while using similar conversation architecture elements. One of the factors is users' experience with CAs, as Gnewuch et al. \cite{gnewuch2018faster}\cmt{[19]} found that experienced users perceived the agent with a response delay as lower in social presence because it is seen as inefficient to wait for the CA to respond, but novice users perceived higher social presence conversing with the CAs using response delays because it is more similar to conversations with human partners \cite{gnewuch2018faster}\cmt{[19]}. User characteristics is another factor, as the perceived trustworthiness of a style matching agent depended on users' own conversational style \cite{hoegen2019end}\cmt{[31]}. Some other contextual factors that resulted in differences in perceptions of agent include the purpose of conversation (e.g. transactional vs. social) \cite{jeong2019exploring}\cmt{[10]}, anonymity of the conversation \cite{lee2020hear}\cmt{[23]}, and the sensitivity of information discussed in the interaction \cite{cox2022does}\cmt{[27]}. A comprehensive review to identify these contextual factors as well as to understand their effects on the perceptions of agents across various conversation architecture elements would be useful to tailor CA design for specific situations. 

As we gain a better understanding about the effects of a single conversation architecture element on the perceptions of agents, we can extend the research to using \textit{multiple conversation architecture elements} in an agent. Several papers in our reviewed corpus incorporated composite elements in an agent, such as the design of an anthropomorphized chatbot using elements such as affective language, emoticons, response delays to assess users' perceptions compared to a non-anthropomorphized chatbot \cite{seeger2021chatbots}\cmt{[35]}. In addition to explore the combined effects of conversation architecture elements on users' perceptions, it would also be interesting to understand the relative importance of each element on perceptions. Some studies analyzed the effect of modifying conversation architecture elements individually, as well as their combined effect on user's perceptions (e.g. \cite{habler2019effects, lubold2016effects, zhu2022effects}\cmt{[63][86][26]}). Specifically, Habler et al. \cite{habler2019effects}\cmt{[63]} found that the effect for social dialog is higher than the effect for prosody on the perception of agents. 


\subsection{Ethical Considerations}

The designers of conversational agents need to consider ethical implications and potential negative impacts for users. This section discusses three main areas of concerns related to the effect of conversation architecture on the perceptions of agents: gender stereotypes, influencing user's actions and privacy concerns.

For the element of prosody, various studies in our corpus explored the effect of different pitches on the perceptions of agents. Even in studies that are not explicitly analyzing the effect of different gendered voices in an agent, possible stereotypes may still exist in the study. Based on our reviewed corpus, studies found that lower pitches commonly associated with men are considered to be more desirable, authoritative but less friendly \cite{jestin2022effects, tolmeijer2021female}\cmt{[81][62]}. For Dubiel et al's study \cite{dubiel2020persuasive}\cmt{[60]}, the agent with lower mean pitch was selected as the more persuasive voice. These results may be demonstrating users' unconscious bias to select a male sounding voice as more persuasive and authoritative over female sounding voices that are commonly associated with higher pitches. While some guidelines recommend designing agents to be androgynous to avoid gender stereotypes \cite{ruane2019conversational}, there are limitations in creating gender-ambiguous voices. Currently there is no defined guidelines on what is perceived as a gender-neutral voice \cite{jestin2022effects}\cmt{[81]}. There is also a lack of voice generators available to generate voices that are perceived as androgynous \cite{tolmeijer2021female}\cmt{[62]}.

Studies have demonstrated that conversation architecture elements can be used to design perceptions of agents to make CAs more persuasive. This opens up the ethical issue of influencing users' attitudes and behaviours through these persuasion techniques. In a study by Chan et al \cite{chan2021kinvoices}\cmt{[74]}, they found that CAs using kin's voices are perceived as more credible and likeable, with a higher perceived social presence with the agent. These perceptions contributes to the agent being more engaging and persuasive, therefore people are more likely to comply with its requests. Andrew et al \cite{andrews2012system}\cmt{[38]} found that tailoring the personality of the CA to users will positively impact an agent's persuasiveness. These persuasion techniques can be beneficial to help users achieve their goals, but can also be used for harmful actions, such as trying to get users to believe in false information.

Another key area of concern is privacy. Given the natural language format of conversational agents, users may be disclosing more sensitive and personal information than needed for the interaction. In relationship to conversation architecture, using elements like self-disclosure and persuasive voice prosody settings could result in users perceiving higher trust with the agent, leading them to disclose more sensitive information  \cite{dubiel2020persuasive, lee2020hear}\cmt{[60][23]}. This can expose users to attacks, such as CAs using voice impersonation to ask for personal information for malicious intents \cite{chan2021kinvoices}\cmt{[74]}. Designing for perceptions of agents requires careful consideration of privacy issues including the sensitivity of the data, who has access to it, and how to protect against nefarious users.

\subsection{Limitations}

Our systematic literature review was limited to papers published in the ACM Digital Library between 2010 and 2022. We may have missed literature published outside this time period, as well as in other libraries. Also, most of the studies in our corpus are based on lab experiments using short interactions with users. The generalizability of these findings need to be verified through longer term engagements with conversational agents deployed in real world situations. Lastly, research without empirical studies on the perception of agents are excluded based on our selection criteria. We may have missed some influential findings in these papers. %To better understand the relationships between conversation architecture elements and the perceptions of agents, we plan to conduct future reviews in literature and user studies to understand their real-world impacts.