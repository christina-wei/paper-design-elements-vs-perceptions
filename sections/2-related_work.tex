%% RELATED WORK SECTION %%

\section{Related Work}

Communication with conversational agents is similar to communicating with humans as they both use natural languages for the interaction. While it is tempting to leverage components from human-human conversation in designing interactions with conversational agents, studies have demonstrated that there are differences between human-human communications and human-agent communications. Currently people consider CAs as a user-controlled tool rather than a social companion, with focuses on the utilitarian aspects of the conversation \cite{clark2019makes}\cmt{[1]}. When conversing with conversational agents, users tend to use shorter messages with limited vocabulary, adapting to the style of the agent \cite{hill2015real}. Also, some studies found that small talk and humour are considered unnecessary or even inauthentic in conversations with CAs, while these elements are important in scaffolding communications with human partners \cite{clark2019makes, doyle2019mapping}\cmt{[1],[2]}. There are also machine-like traits that users preferred in a CA, such as the ability to interact through multimodal media, and a machine's perceived ability to be objective and non-judgemental \cite{doyle2019mapping, kim2022understanding}\cmt{[2],[3]}. Given human-agent communications are different from human-human communications, it is important to look specifically at the design of user experiences for conversational agents.

There have been numerous studies on the user experiences for conversational agents, and some attempts to synthesize findings across literature. Several papers have mapped out the current state of research for conversational agents for specific agent types (e.g. text-based, voice-based, polyadic) highlighting major trends, topics, methods and evaluating metrics \cite{clark2019state, rapp2021human, zheng2022ux}\cmt{[33][5]}. Other papers looked at specific dimensions of user experiences or domains of usage, such as Van Pinxteren et al. \cite{van2020human} examining the effects of agents' human-like communicative behaviours on their relationships with users, and Kocaballi et al. \cite{kocaballi2022design} exploring the challenges and opportunities of CAs in healthcare. There are also publications aimed to unify concepts used in the research for CA user experiences, for instance Feine et al. \cite{feine2019taxonomy} creating a taxonomy of social cues, and Finch et al. \cite{finch2020towards} analyzing evaluation protocols for dialogue systems. To the best of our knowledge, there is currently no synthesis on the speech specifics of CAs, the perceptions of agents, or the relationship between them.

Conversation architecture has been demonstrated to play an important role in users' perceptions of agents \cite{knijnenburg2016inferring, moussawi2021perceptions, seeger2021chatbots}\cmt{[35]}. Yet, little is known about the overall landscape on the how the specifics of speech variations affect these perceptions. Given the paucity of research in this area, this paper aims to synthesize the identified relationships between conversation architecture elements and users' perceptions of agents.

%Other papers categorized CA assessments into themes. For example, Rapp et al. \cite{rapp2021human} generated themes related to how users' experience with chatbots such as experiencing the chatbot including assessments on expectation, perception, satisfaction etc.  Most recently, Zheng et al's literature review on the UX research of CAs \cite{zheng2022ux} categorized the metrics based on the type of method used, including technical measures like system error rate and perception measures like perceived social presence. However, existing studies use different terminologies and categories across aspects of perception. As an illustration, it is unclear if the theme of experiencing the chatbot from Rapp et al. \cite{rapp2021human} contains similar aspects to the perception towards CA in Zheng et al \cite{zheng2022ux}'s analysis.
%\cite{finch2020towards} Towards unified dialogue system evaluation: A comprehensive analysis of current evaluation protocols

%Anthropomorphism is defined as the attribution of traits that we typically associate with being distinctly human to nonhuman entities \cite{waytz2010sees}. For example, users tend to personify conversational agents like Amazon Alexa by using person pronouns instead of object pronouns in online reviews \cite{purington2017alexa}.  Research shows that anthropomorphic design is beneficial to establishing and maintaining trust between users and conversational agents \cite{seeger2021chatbots}. Also, speakers tend to align their lexical choices with conversational agents, similar to human-human conversations \cite{cowan2015does}. Anthropomorphism has been shown to ease user interactions, e.g. making agents more approachable, engaging, and trustworthy when they exhibit human characteristics \cite{qiu2009evaluating}. These processes are of particular interest for human-agent communication because they form the basis for user expectations and predispositions regarding agents' behavior, reliability of the information, etc. \cite{kuzminykh2020genie}.